{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Glioblastoma Survival Outcomes from Radiomic Features\n",
    "Udacity Machine Learning Engineer Nanodegree <br>\n",
    "Kareem Wahid <br>\n",
    "Last updated: June 13, 2017 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import functools\n",
    "\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brats17ID</th>\n",
       "      <th>Image</th>\n",
       "      <th>Mask</th>\n",
       "      <th>Age</th>\n",
       "      <th>Survival</th>\n",
       "      <th>general_info_BoundingBox</th>\n",
       "      <th>general_info_GeneralSettings</th>\n",
       "      <th>general_info_ImageHash</th>\n",
       "      <th>general_info_ImageSpacing</th>\n",
       "      <th>general_info_InputImages</th>\n",
       "      <th>...</th>\n",
       "      <th>original_glszm_LargeAreaEmphasis</th>\n",
       "      <th>original_glszm_ZoneVariance</th>\n",
       "      <th>original_glszm_ZonePercentage</th>\n",
       "      <th>original_glszm_LargeAreaLowGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_LargeAreaHighGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_HighGrayLevelZoneEmphasis</th>\n",
       "      <th>original_glszm_SmallAreaEmphasis</th>\n",
       "      <th>original_glszm_LowGrayLevelZoneEmphasis</th>\n",
       "      <th>original_glszm_ZoneEntropy</th>\n",
       "      <th>original_glszm_SmallAreaLowGrayLevelEmphasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brats17_2013_11_1</td>\n",
       "      <td>Brats17_2013_11_1_flair.nii</td>\n",
       "      <td>Brats17_2013_11_1_seg.nii</td>\n",
       "      <td>29.120</td>\n",
       "      <td>150</td>\n",
       "      <td>(115, 88, 45, 58, 60, 60)</td>\n",
       "      <td>{'distances': [1], 'additionalInfo': True, 'en...</td>\n",
       "      <td>286516874ed6844f101e6d495353bde3b486861c</td>\n",
       "      <td>(1.0, 1.0, 1.0)</td>\n",
       "      <td>{'Original': {}}</td>\n",
       "      <td>...</td>\n",
       "      <td>791718.179138</td>\n",
       "      <td>780913.967308</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>14936.565425</td>\n",
       "      <td>4.857379e+07</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.498430</td>\n",
       "      <td>0.034596</td>\n",
       "      <td>5.630367</td>\n",
       "      <td>0.017143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brats17_2013_27_1</td>\n",
       "      <td>Brats17_2013_27_1_flair.nii</td>\n",
       "      <td>Brats17_2013_27_1_seg.nii</td>\n",
       "      <td>68.020</td>\n",
       "      <td>120</td>\n",
       "      <td>(138, 87, 34, 42, 49, 38)</td>\n",
       "      <td>{'distances': [1], 'additionalInfo': True, 'en...</td>\n",
       "      <td>c36bad577d6f4cd0280bad746e50f7bcdd2e372e</td>\n",
       "      <td>(1.0, 1.0, 1.0)</td>\n",
       "      <td>{'Original': {}}</td>\n",
       "      <td>...</td>\n",
       "      <td>126628.990698</td>\n",
       "      <td>123653.922466</td>\n",
       "      <td>0.018334</td>\n",
       "      <td>1818.903693</td>\n",
       "      <td>9.088362e+06</td>\n",
       "      <td>73.655814</td>\n",
       "      <td>0.526228</td>\n",
       "      <td>0.050365</td>\n",
       "      <td>5.748432</td>\n",
       "      <td>0.030350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brats17_CBICA_AAB_1</td>\n",
       "      <td>Brats17_CBICA_AAB_1_flair.nii</td>\n",
       "      <td>Brats17_CBICA_AAB_1_seg.nii</td>\n",
       "      <td>60.463</td>\n",
       "      <td>289</td>\n",
       "      <td>(70, 102, 41, 50, 56, 37)</td>\n",
       "      <td>{'distances': [1], 'additionalInfo': True, 'en...</td>\n",
       "      <td>4daf9033b834149980edf93394857021e411d107</td>\n",
       "      <td>(1.0, 1.0, 1.0)</td>\n",
       "      <td>{'Original': {}}</td>\n",
       "      <td>...</td>\n",
       "      <td>33324.827080</td>\n",
       "      <td>32690.165229</td>\n",
       "      <td>0.039694</td>\n",
       "      <td>763.749453</td>\n",
       "      <td>2.027000e+06</td>\n",
       "      <td>78.017945</td>\n",
       "      <td>0.488117</td>\n",
       "      <td>0.025907</td>\n",
       "      <td>6.093996</td>\n",
       "      <td>0.014043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brats17_CBICA_AAG_1</td>\n",
       "      <td>Brats17_CBICA_AAG_1_flair.nii</td>\n",
       "      <td>Brats17_CBICA_AAG_1_seg.nii</td>\n",
       "      <td>52.263</td>\n",
       "      <td>616</td>\n",
       "      <td>(67, 86, 37, 28, 32, 34)</td>\n",
       "      <td>{'distances': [1], 'additionalInfo': True, 'en...</td>\n",
       "      <td>743d470b1be0e8ca7c06b83dd76f6c9664ee91df</td>\n",
       "      <td>(1.0, 1.0, 1.0)</td>\n",
       "      <td>{'Original': {}}</td>\n",
       "      <td>...</td>\n",
       "      <td>7202.748728</td>\n",
       "      <td>7115.915907</td>\n",
       "      <td>0.107314</td>\n",
       "      <td>105.475729</td>\n",
       "      <td>5.429043e+05</td>\n",
       "      <td>218.376399</td>\n",
       "      <td>0.634989</td>\n",
       "      <td>0.011227</td>\n",
       "      <td>6.182728</td>\n",
       "      <td>0.007220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brats17_CBICA_AAL_1</td>\n",
       "      <td>Brats17_CBICA_AAL_1_flair.nii</td>\n",
       "      <td>Brats17_CBICA_AAL_1_seg.nii</td>\n",
       "      <td>54.301</td>\n",
       "      <td>464</td>\n",
       "      <td>(160, 149, 61, 16, 19, 18)</td>\n",
       "      <td>{'distances': [1], 'additionalInfo': True, 'en...</td>\n",
       "      <td>460c029d619f0370f008ef35376105152290857e</td>\n",
       "      <td>(1.0, 1.0, 1.0)</td>\n",
       "      <td>{'Original': {}}</td>\n",
       "      <td>...</td>\n",
       "      <td>2954.224490</td>\n",
       "      <td>2730.447314</td>\n",
       "      <td>0.066849</td>\n",
       "      <td>396.438798</td>\n",
       "      <td>2.555706e+04</td>\n",
       "      <td>11.857143</td>\n",
       "      <td>0.586383</td>\n",
       "      <td>0.197392</td>\n",
       "      <td>4.051376</td>\n",
       "      <td>0.120535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brats17ID                          Image  \\\n",
       "0    Brats17_2013_11_1    Brats17_2013_11_1_flair.nii   \n",
       "1    Brats17_2013_27_1    Brats17_2013_27_1_flair.nii   \n",
       "2  Brats17_CBICA_AAB_1  Brats17_CBICA_AAB_1_flair.nii   \n",
       "3  Brats17_CBICA_AAG_1  Brats17_CBICA_AAG_1_flair.nii   \n",
       "4  Brats17_CBICA_AAL_1  Brats17_CBICA_AAL_1_flair.nii   \n",
       "\n",
       "                          Mask     Age  Survival    general_info_BoundingBox  \\\n",
       "0    Brats17_2013_11_1_seg.nii  29.120       150   (115, 88, 45, 58, 60, 60)   \n",
       "1    Brats17_2013_27_1_seg.nii  68.020       120   (138, 87, 34, 42, 49, 38)   \n",
       "2  Brats17_CBICA_AAB_1_seg.nii  60.463       289   (70, 102, 41, 50, 56, 37)   \n",
       "3  Brats17_CBICA_AAG_1_seg.nii  52.263       616    (67, 86, 37, 28, 32, 34)   \n",
       "4  Brats17_CBICA_AAL_1_seg.nii  54.301       464  (160, 149, 61, 16, 19, 18)   \n",
       "\n",
       "                        general_info_GeneralSettings  \\\n",
       "0  {'distances': [1], 'additionalInfo': True, 'en...   \n",
       "1  {'distances': [1], 'additionalInfo': True, 'en...   \n",
       "2  {'distances': [1], 'additionalInfo': True, 'en...   \n",
       "3  {'distances': [1], 'additionalInfo': True, 'en...   \n",
       "4  {'distances': [1], 'additionalInfo': True, 'en...   \n",
       "\n",
       "                     general_info_ImageHash general_info_ImageSpacing  \\\n",
       "0  286516874ed6844f101e6d495353bde3b486861c           (1.0, 1.0, 1.0)   \n",
       "1  c36bad577d6f4cd0280bad746e50f7bcdd2e372e           (1.0, 1.0, 1.0)   \n",
       "2  4daf9033b834149980edf93394857021e411d107           (1.0, 1.0, 1.0)   \n",
       "3  743d470b1be0e8ca7c06b83dd76f6c9664ee91df           (1.0, 1.0, 1.0)   \n",
       "4  460c029d619f0370f008ef35376105152290857e           (1.0, 1.0, 1.0)   \n",
       "\n",
       "  general_info_InputImages                      ...                       \\\n",
       "0         {'Original': {}}                      ...                        \n",
       "1         {'Original': {}}                      ...                        \n",
       "2         {'Original': {}}                      ...                        \n",
       "3         {'Original': {}}                      ...                        \n",
       "4         {'Original': {}}                      ...                        \n",
       "\n",
       "  original_glszm_LargeAreaEmphasis original_glszm_ZoneVariance  \\\n",
       "0                    791718.179138               780913.967308   \n",
       "1                    126628.990698               123653.922466   \n",
       "2                     33324.827080                32690.165229   \n",
       "3                      7202.748728                 7115.915907   \n",
       "4                      2954.224490                 2730.447314   \n",
       "\n",
       "   original_glszm_ZonePercentage  \\\n",
       "0                       0.009621   \n",
       "1                       0.018334   \n",
       "2                       0.039694   \n",
       "3                       0.107314   \n",
       "4                       0.066849   \n",
       "\n",
       "   original_glszm_LargeAreaLowGrayLevelEmphasis  \\\n",
       "0                                  14936.565425   \n",
       "1                                   1818.903693   \n",
       "2                                    763.749453   \n",
       "3                                    105.475729   \n",
       "4                                    396.438798   \n",
       "\n",
       "   original_glszm_LargeAreaHighGrayLevelEmphasis  \\\n",
       "0                                   4.857379e+07   \n",
       "1                                   9.088362e+06   \n",
       "2                                   2.027000e+06   \n",
       "3                                   5.429043e+05   \n",
       "4                                   2.555706e+04   \n",
       "\n",
       "   original_glszm_HighGrayLevelZoneEmphasis  original_glszm_SmallAreaEmphasis  \\\n",
       "0                                 55.000000                          0.498430   \n",
       "1                                 73.655814                          0.526228   \n",
       "2                                 78.017945                          0.488117   \n",
       "3                                218.376399                          0.634989   \n",
       "4                                 11.857143                          0.586383   \n",
       "\n",
       "   original_glszm_LowGrayLevelZoneEmphasis  original_glszm_ZoneEntropy  \\\n",
       "0                                 0.034596                    5.630367   \n",
       "1                                 0.050365                    5.748432   \n",
       "2                                 0.025907                    6.093996   \n",
       "3                                 0.011227                    6.182728   \n",
       "4                                 0.197392                    4.051376   \n",
       "\n",
       "   original_glszm_SmallAreaLowGrayLevelEmphasis  \n",
       "0                                      0.017143  \n",
       "1                                      0.030350  \n",
       "2                                      0.014043  \n",
       "3                                      0.007220  \n",
       "4                                      0.120535  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radiomic_raw = pd.read_csv('radiomics_output_WITHSURVIVAL_raw.csv')\n",
    "radiomic_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEFCAYAAAD5bXAgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK1BpQdsvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1143bbb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = sns.distplot(radiomic_raw['Survival']) # Plot surival data \n",
    "plot.set_xlabel('Survival (days)')\n",
    "fig = plot.get_figure()\n",
    "\n",
    "#fig.savefig(\"Survival_distribution.pdf\", bbox_inches='tight') # Uncomment to save plot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove rows with NaN values and unnecessary columns\n",
    "Remove all rows with NaN values (geometry mismatch) and the unnecessary columns from the dataset such General Info about the radiomics algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survival</th>\n",
       "      <th>original_shape_Maximum3DDiameter</th>\n",
       "      <th>original_shape_Compactness2</th>\n",
       "      <th>original_shape_Maximum2DDiameterSlice</th>\n",
       "      <th>original_shape_Sphericity</th>\n",
       "      <th>original_shape_MinorAxis</th>\n",
       "      <th>original_shape_Compactness1</th>\n",
       "      <th>original_shape_Elongation</th>\n",
       "      <th>original_shape_SurfaceVolumeRatio</th>\n",
       "      <th>original_shape_Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>original_glszm_LargeAreaEmphasis</th>\n",
       "      <th>original_glszm_ZoneVariance</th>\n",
       "      <th>original_glszm_ZonePercentage</th>\n",
       "      <th>original_glszm_LargeAreaLowGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_LargeAreaHighGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_HighGrayLevelZoneEmphasis</th>\n",
       "      <th>original_glszm_SmallAreaEmphasis</th>\n",
       "      <th>original_glszm_LowGrayLevelZoneEmphasis</th>\n",
       "      <th>original_glszm_ZoneEntropy</th>\n",
       "      <th>original_glszm_SmallAreaLowGrayLevelEmphasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>72.367120</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>60.827625</td>\n",
       "      <td>0.283090</td>\n",
       "      <td>40.724522</td>\n",
       "      <td>0.007991</td>\n",
       "      <td>0.712809</td>\n",
       "      <td>0.477325</td>\n",
       "      <td>45839.0</td>\n",
       "      <td>...</td>\n",
       "      <td>791718.179138</td>\n",
       "      <td>780913.967308</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>14936.565425</td>\n",
       "      <td>4.857379e+07</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.498430</td>\n",
       "      <td>0.034596</td>\n",
       "      <td>5.630367</td>\n",
       "      <td>0.017143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>51.584882</td>\n",
       "      <td>0.032489</td>\n",
       "      <td>44.922155</td>\n",
       "      <td>0.319089</td>\n",
       "      <td>28.339747</td>\n",
       "      <td>0.009562</td>\n",
       "      <td>0.731216</td>\n",
       "      <td>0.667079</td>\n",
       "      <td>11727.0</td>\n",
       "      <td>...</td>\n",
       "      <td>126628.990698</td>\n",
       "      <td>123653.922466</td>\n",
       "      <td>0.018334</td>\n",
       "      <td>1818.903693</td>\n",
       "      <td>9.088362e+06</td>\n",
       "      <td>73.655814</td>\n",
       "      <td>0.526228</td>\n",
       "      <td>0.050365</td>\n",
       "      <td>5.748432</td>\n",
       "      <td>0.030350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.038263</td>\n",
       "      <td>50.009999</td>\n",
       "      <td>0.336971</td>\n",
       "      <td>36.852581</td>\n",
       "      <td>0.010377</td>\n",
       "      <td>0.731829</td>\n",
       "      <td>0.576298</td>\n",
       "      <td>15443.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33324.827080</td>\n",
       "      <td>32690.165229</td>\n",
       "      <td>0.039694</td>\n",
       "      <td>763.749453</td>\n",
       "      <td>2.027000e+06</td>\n",
       "      <td>78.017945</td>\n",
       "      <td>0.488117</td>\n",
       "      <td>0.025907</td>\n",
       "      <td>6.093996</td>\n",
       "      <td>0.014043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>616</td>\n",
       "      <td>34.655447</td>\n",
       "      <td>0.397477</td>\n",
       "      <td>30.149627</td>\n",
       "      <td>0.735254</td>\n",
       "      <td>24.172434</td>\n",
       "      <td>0.033447</td>\n",
       "      <td>0.805201</td>\n",
       "      <td>0.314351</td>\n",
       "      <td>9160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7202.748728</td>\n",
       "      <td>7115.915907</td>\n",
       "      <td>0.107314</td>\n",
       "      <td>105.475729</td>\n",
       "      <td>5.429043e+05</td>\n",
       "      <td>218.376399</td>\n",
       "      <td>0.634989</td>\n",
       "      <td>0.011227</td>\n",
       "      <td>6.182728</td>\n",
       "      <td>0.007220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>464</td>\n",
       "      <td>21.470911</td>\n",
       "      <td>0.076978</td>\n",
       "      <td>17.464249</td>\n",
       "      <td>0.425392</td>\n",
       "      <td>12.284284</td>\n",
       "      <td>0.014719</td>\n",
       "      <td>0.768372</td>\n",
       "      <td>1.260841</td>\n",
       "      <td>733.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2954.224490</td>\n",
       "      <td>2730.447314</td>\n",
       "      <td>0.066849</td>\n",
       "      <td>396.438798</td>\n",
       "      <td>2.555706e+04</td>\n",
       "      <td>11.857143</td>\n",
       "      <td>0.586383</td>\n",
       "      <td>0.197392</td>\n",
       "      <td>4.051376</td>\n",
       "      <td>0.120535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survival  original_shape_Maximum3DDiameter  original_shape_Compactness2  \\\n",
       "0       150                         72.367120                     0.022687   \n",
       "1       120                         51.584882                     0.032489   \n",
       "2       289                         63.000000                     0.038263   \n",
       "3       616                         34.655447                     0.397477   \n",
       "4       464                         21.470911                     0.076978   \n",
       "\n",
       "   original_shape_Maximum2DDiameterSlice  original_shape_Sphericity  \\\n",
       "0                              60.827625                   0.283090   \n",
       "1                              44.922155                   0.319089   \n",
       "2                              50.009999                   0.336971   \n",
       "3                              30.149627                   0.735254   \n",
       "4                              17.464249                   0.425392   \n",
       "\n",
       "   original_shape_MinorAxis  original_shape_Compactness1  \\\n",
       "0                 40.724522                     0.007991   \n",
       "1                 28.339747                     0.009562   \n",
       "2                 36.852581                     0.010377   \n",
       "3                 24.172434                     0.033447   \n",
       "4                 12.284284                     0.014719   \n",
       "\n",
       "   original_shape_Elongation  original_shape_SurfaceVolumeRatio  \\\n",
       "0                   0.712809                           0.477325   \n",
       "1                   0.731216                           0.667079   \n",
       "2                   0.731829                           0.576298   \n",
       "3                   0.805201                           0.314351   \n",
       "4                   0.768372                           1.260841   \n",
       "\n",
       "   original_shape_Volume                      ...                       \\\n",
       "0                45839.0                      ...                        \n",
       "1                11727.0                      ...                        \n",
       "2                15443.0                      ...                        \n",
       "3                 9160.0                      ...                        \n",
       "4                  733.0                      ...                        \n",
       "\n",
       "   original_glszm_LargeAreaEmphasis  original_glszm_ZoneVariance  \\\n",
       "0                     791718.179138                780913.967308   \n",
       "1                     126628.990698                123653.922466   \n",
       "2                      33324.827080                 32690.165229   \n",
       "3                       7202.748728                  7115.915907   \n",
       "4                       2954.224490                  2730.447314   \n",
       "\n",
       "   original_glszm_ZonePercentage  \\\n",
       "0                       0.009621   \n",
       "1                       0.018334   \n",
       "2                       0.039694   \n",
       "3                       0.107314   \n",
       "4                       0.066849   \n",
       "\n",
       "   original_glszm_LargeAreaLowGrayLevelEmphasis  \\\n",
       "0                                  14936.565425   \n",
       "1                                   1818.903693   \n",
       "2                                    763.749453   \n",
       "3                                    105.475729   \n",
       "4                                    396.438798   \n",
       "\n",
       "   original_glszm_LargeAreaHighGrayLevelEmphasis  \\\n",
       "0                                   4.857379e+07   \n",
       "1                                   9.088362e+06   \n",
       "2                                   2.027000e+06   \n",
       "3                                   5.429043e+05   \n",
       "4                                   2.555706e+04   \n",
       "\n",
       "   original_glszm_HighGrayLevelZoneEmphasis  original_glszm_SmallAreaEmphasis  \\\n",
       "0                                 55.000000                          0.498430   \n",
       "1                                 73.655814                          0.526228   \n",
       "2                                 78.017945                          0.488117   \n",
       "3                                218.376399                          0.634989   \n",
       "4                                 11.857143                          0.586383   \n",
       "\n",
       "   original_glszm_LowGrayLevelZoneEmphasis  original_glszm_ZoneEntropy  \\\n",
       "0                                 0.034596                    5.630367   \n",
       "1                                 0.050365                    5.748432   \n",
       "2                                 0.025907                    6.093996   \n",
       "3                                 0.011227                    6.182728   \n",
       "4                                 0.197392                    4.051376   \n",
       "\n",
       "   original_glszm_SmallAreaLowGrayLevelEmphasis  \n",
       "0                                      0.017143  \n",
       "1                                      0.030350  \n",
       "2                                      0.014043  \n",
       "3                                      0.007220  \n",
       "4                                      0.120535  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radiomic_filtered = radiomic_raw[np.isfinite(radiomic_raw['original_glszm_SmallAreaLowGrayLevelEmphasis'])] # Remove all samples with NaN as value\n",
    "del radiomic_filtered['Brats17ID'] \n",
    "del radiomic_filtered['Image']\n",
    "del radiomic_filtered['Mask']\n",
    "del radiomic_filtered['Age']\n",
    "del radiomic_filtered['general_info_BoundingBox']\n",
    "del radiomic_filtered['general_info_GeneralSettings']\n",
    "del radiomic_filtered['general_info_ImageHash']\n",
    "del radiomic_filtered['general_info_ImageSpacing']\n",
    "del radiomic_filtered['general_info_InputImages']\n",
    "del radiomic_filtered['general_info_MaskHash']\n",
    "del radiomic_filtered['general_info_VoxelNum']\n",
    "del radiomic_filtered['general_info_Version']\n",
    "del radiomic_filtered['general_info_VolumeNum']\n",
    "\n",
    "radiomic_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranform survival data into categorical values\n",
    "Transform numerical continous survival values to 0 (short term survivor) and 1 (long term survivor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kareemwahid/anaconda/lib/python2.7/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survival</th>\n",
       "      <th>original_shape_Maximum3DDiameter</th>\n",
       "      <th>original_shape_Compactness2</th>\n",
       "      <th>original_shape_Maximum2DDiameterSlice</th>\n",
       "      <th>original_shape_Sphericity</th>\n",
       "      <th>original_shape_MinorAxis</th>\n",
       "      <th>original_shape_Compactness1</th>\n",
       "      <th>original_shape_Elongation</th>\n",
       "      <th>original_shape_SurfaceVolumeRatio</th>\n",
       "      <th>original_shape_Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>original_glszm_LargeAreaEmphasis</th>\n",
       "      <th>original_glszm_ZoneVariance</th>\n",
       "      <th>original_glszm_ZonePercentage</th>\n",
       "      <th>original_glszm_LargeAreaLowGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_LargeAreaHighGrayLevelEmphasis</th>\n",
       "      <th>original_glszm_HighGrayLevelZoneEmphasis</th>\n",
       "      <th>original_glszm_SmallAreaEmphasis</th>\n",
       "      <th>original_glszm_LowGrayLevelZoneEmphasis</th>\n",
       "      <th>original_glszm_ZoneEntropy</th>\n",
       "      <th>original_glszm_SmallAreaLowGrayLevelEmphasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>72.367120</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>60.827625</td>\n",
       "      <td>0.283090</td>\n",
       "      <td>40.724522</td>\n",
       "      <td>0.007991</td>\n",
       "      <td>0.712809</td>\n",
       "      <td>0.477325</td>\n",
       "      <td>45839.0</td>\n",
       "      <td>...</td>\n",
       "      <td>791718.179138</td>\n",
       "      <td>780913.967308</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>14936.565425</td>\n",
       "      <td>4.857379e+07</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.498430</td>\n",
       "      <td>0.034596</td>\n",
       "      <td>5.630367</td>\n",
       "      <td>0.017143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>51.584882</td>\n",
       "      <td>0.032489</td>\n",
       "      <td>44.922155</td>\n",
       "      <td>0.319089</td>\n",
       "      <td>28.339747</td>\n",
       "      <td>0.009562</td>\n",
       "      <td>0.731216</td>\n",
       "      <td>0.667079</td>\n",
       "      <td>11727.0</td>\n",
       "      <td>...</td>\n",
       "      <td>126628.990698</td>\n",
       "      <td>123653.922466</td>\n",
       "      <td>0.018334</td>\n",
       "      <td>1818.903693</td>\n",
       "      <td>9.088362e+06</td>\n",
       "      <td>73.655814</td>\n",
       "      <td>0.526228</td>\n",
       "      <td>0.050365</td>\n",
       "      <td>5.748432</td>\n",
       "      <td>0.030350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.038263</td>\n",
       "      <td>50.009999</td>\n",
       "      <td>0.336971</td>\n",
       "      <td>36.852581</td>\n",
       "      <td>0.010377</td>\n",
       "      <td>0.731829</td>\n",
       "      <td>0.576298</td>\n",
       "      <td>15443.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33324.827080</td>\n",
       "      <td>32690.165229</td>\n",
       "      <td>0.039694</td>\n",
       "      <td>763.749453</td>\n",
       "      <td>2.027000e+06</td>\n",
       "      <td>78.017945</td>\n",
       "      <td>0.488117</td>\n",
       "      <td>0.025907</td>\n",
       "      <td>6.093996</td>\n",
       "      <td>0.014043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>34.655447</td>\n",
       "      <td>0.397477</td>\n",
       "      <td>30.149627</td>\n",
       "      <td>0.735254</td>\n",
       "      <td>24.172434</td>\n",
       "      <td>0.033447</td>\n",
       "      <td>0.805201</td>\n",
       "      <td>0.314351</td>\n",
       "      <td>9160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7202.748728</td>\n",
       "      <td>7115.915907</td>\n",
       "      <td>0.107314</td>\n",
       "      <td>105.475729</td>\n",
       "      <td>5.429043e+05</td>\n",
       "      <td>218.376399</td>\n",
       "      <td>0.634989</td>\n",
       "      <td>0.011227</td>\n",
       "      <td>6.182728</td>\n",
       "      <td>0.007220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>21.470911</td>\n",
       "      <td>0.076978</td>\n",
       "      <td>17.464249</td>\n",
       "      <td>0.425392</td>\n",
       "      <td>12.284284</td>\n",
       "      <td>0.014719</td>\n",
       "      <td>0.768372</td>\n",
       "      <td>1.260841</td>\n",
       "      <td>733.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2954.224490</td>\n",
       "      <td>2730.447314</td>\n",
       "      <td>0.066849</td>\n",
       "      <td>396.438798</td>\n",
       "      <td>2.555706e+04</td>\n",
       "      <td>11.857143</td>\n",
       "      <td>0.586383</td>\n",
       "      <td>0.197392</td>\n",
       "      <td>4.051376</td>\n",
       "      <td>0.120535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survival  original_shape_Maximum3DDiameter  original_shape_Compactness2  \\\n",
       "0         0                         72.367120                     0.022687   \n",
       "1         0                         51.584882                     0.032489   \n",
       "2         0                         63.000000                     0.038263   \n",
       "3         1                         34.655447                     0.397477   \n",
       "4         1                         21.470911                     0.076978   \n",
       "\n",
       "   original_shape_Maximum2DDiameterSlice  original_shape_Sphericity  \\\n",
       "0                              60.827625                   0.283090   \n",
       "1                              44.922155                   0.319089   \n",
       "2                              50.009999                   0.336971   \n",
       "3                              30.149627                   0.735254   \n",
       "4                              17.464249                   0.425392   \n",
       "\n",
       "   original_shape_MinorAxis  original_shape_Compactness1  \\\n",
       "0                 40.724522                     0.007991   \n",
       "1                 28.339747                     0.009562   \n",
       "2                 36.852581                     0.010377   \n",
       "3                 24.172434                     0.033447   \n",
       "4                 12.284284                     0.014719   \n",
       "\n",
       "   original_shape_Elongation  original_shape_SurfaceVolumeRatio  \\\n",
       "0                   0.712809                           0.477325   \n",
       "1                   0.731216                           0.667079   \n",
       "2                   0.731829                           0.576298   \n",
       "3                   0.805201                           0.314351   \n",
       "4                   0.768372                           1.260841   \n",
       "\n",
       "   original_shape_Volume                      ...                       \\\n",
       "0                45839.0                      ...                        \n",
       "1                11727.0                      ...                        \n",
       "2                15443.0                      ...                        \n",
       "3                 9160.0                      ...                        \n",
       "4                  733.0                      ...                        \n",
       "\n",
       "   original_glszm_LargeAreaEmphasis  original_glszm_ZoneVariance  \\\n",
       "0                     791718.179138                780913.967308   \n",
       "1                     126628.990698                123653.922466   \n",
       "2                      33324.827080                 32690.165229   \n",
       "3                       7202.748728                  7115.915907   \n",
       "4                       2954.224490                  2730.447314   \n",
       "\n",
       "   original_glszm_ZonePercentage  \\\n",
       "0                       0.009621   \n",
       "1                       0.018334   \n",
       "2                       0.039694   \n",
       "3                       0.107314   \n",
       "4                       0.066849   \n",
       "\n",
       "   original_glszm_LargeAreaLowGrayLevelEmphasis  \\\n",
       "0                                  14936.565425   \n",
       "1                                   1818.903693   \n",
       "2                                    763.749453   \n",
       "3                                    105.475729   \n",
       "4                                    396.438798   \n",
       "\n",
       "   original_glszm_LargeAreaHighGrayLevelEmphasis  \\\n",
       "0                                   4.857379e+07   \n",
       "1                                   9.088362e+06   \n",
       "2                                   2.027000e+06   \n",
       "3                                   5.429043e+05   \n",
       "4                                   2.555706e+04   \n",
       "\n",
       "   original_glszm_HighGrayLevelZoneEmphasis  original_glszm_SmallAreaEmphasis  \\\n",
       "0                                 55.000000                          0.498430   \n",
       "1                                 73.655814                          0.526228   \n",
       "2                                 78.017945                          0.488117   \n",
       "3                                218.376399                          0.634989   \n",
       "4                                 11.857143                          0.586383   \n",
       "\n",
       "   original_glszm_LowGrayLevelZoneEmphasis  original_glszm_ZoneEntropy  \\\n",
       "0                                 0.034596                    5.630367   \n",
       "1                                 0.050365                    5.748432   \n",
       "2                                 0.025907                    6.093996   \n",
       "3                                 0.011227                    6.182728   \n",
       "4                                 0.197392                    4.051376   \n",
       "\n",
       "   original_glszm_SmallAreaLowGrayLevelEmphasis  \n",
       "0                                      0.017143  \n",
       "1                                      0.030350  \n",
       "2                                      0.014043  \n",
       "3                                      0.007220  \n",
       "4                                      0.120535  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radiomic_filtered.loc[radiomic_filtered.Survival < 360, 'Survival'] = 0\n",
    "radiomic_filtered.loc[radiomic_filtered.Survival >= 360, 'Survival'] = 1\n",
    "\n",
    "radiomic_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival classes distribution after data cleaning and stratifying\n",
    "Survival classes are shown to be approximatley equal after stratification process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEHCAYAAABCwJb2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSRUx9CWpIv8HHg9AWpef20gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117f77810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make plot\n",
    "survivalbox = sns.countplot(x=\"Survival\", data = radiomic_filtered)\n",
    "\n",
    "# Modify plot\n",
    "survivalbox.set_xlabel('Survival Class')\n",
    "fig = survivalbox.get_figure()\n",
    "\n",
    "#fig.savefig(\"Survival_0_1_distribution.pdf\", bbox_inches='tight') # Uncomment to save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Statistics Table for select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_firstorder_Variance</th>\n",
       "      <th>original_shape_Volume</th>\n",
       "      <th>original_glcm_Autocorrelation</th>\n",
       "      <th>original_glszm_SmallAreaEmphasis</th>\n",
       "      <th>original_glrlm_ShortRunEmphasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8643.939274</td>\n",
       "      <td>11856.813333</td>\n",
       "      <td>190.708194</td>\n",
       "      <td>0.552885</td>\n",
       "      <td>0.809201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14328.384058</td>\n",
       "      <td>14355.168518</td>\n",
       "      <td>215.694998</td>\n",
       "      <td>0.076401</td>\n",
       "      <td>0.100613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.583814</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>5.112822</td>\n",
       "      <td>0.334238</td>\n",
       "      <td>0.313110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2034.993231</td>\n",
       "      <td>3274.750000</td>\n",
       "      <td>67.445700</td>\n",
       "      <td>0.497041</td>\n",
       "      <td>0.746117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4273.065840</td>\n",
       "      <td>7820.500000</td>\n",
       "      <td>118.009713</td>\n",
       "      <td>0.564855</td>\n",
       "      <td>0.838175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8120.411208</td>\n",
       "      <td>15919.750000</td>\n",
       "      <td>240.788684</td>\n",
       "      <td>0.605882</td>\n",
       "      <td>0.875534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98968.979609</td>\n",
       "      <td>91299.000000</td>\n",
       "      <td>1329.476095</td>\n",
       "      <td>0.740891</td>\n",
       "      <td>0.960379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       original_firstorder_Variance  original_shape_Volume  \\\n",
       "count                    150.000000             150.000000   \n",
       "mean                    8643.939274           11856.813333   \n",
       "std                    14328.384058           14355.168518   \n",
       "min                       20.583814              47.000000   \n",
       "25%                     2034.993231            3274.750000   \n",
       "50%                     4273.065840            7820.500000   \n",
       "75%                     8120.411208           15919.750000   \n",
       "max                    98968.979609           91299.000000   \n",
       "\n",
       "       original_glcm_Autocorrelation  original_glszm_SmallAreaEmphasis  \\\n",
       "count                     150.000000                        150.000000   \n",
       "mean                      190.708194                          0.552885   \n",
       "std                       215.694998                          0.076401   \n",
       "min                         5.112822                          0.334238   \n",
       "25%                        67.445700                          0.497041   \n",
       "50%                       118.009713                          0.564855   \n",
       "75%                       240.788684                          0.605882   \n",
       "max                      1329.476095                          0.740891   \n",
       "\n",
       "       original_glrlm_ShortRunEmphasis  \n",
       "count                       150.000000  \n",
       "mean                          0.809201  \n",
       "std                           0.100613  \n",
       "min                           0.313110  \n",
       "25%                           0.746117  \n",
       "50%                           0.838175  \n",
       "75%                           0.875534  \n",
       "max                           0.960379  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radiomic_filtered[['original_firstorder_Variance','original_shape_Volume', 'original_glcm_Autocorrelation', \n",
    "               'original_glszm_SmallAreaEmphasis', 'original_glrlm_ShortRunEmphasis']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplot of two shape features\n",
    "\n",
    "Short term survivors show only sliglty higher tumor volume and diameter when compared to long term survivors. This highlights the need to consider more than just the tumor shape when analyzing a MRI image of Glioblastoma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x11801edd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAFkCAYAAAA+MHziAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wFfdwBVZ7rSjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11801ec90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make plot\n",
    "shapescatter = sns.lmplot(x=\"original_shape_Volume\", y=\"original_shape_Maximum3DDiameter\", hue = 'Survival',\n",
    "                 data = radiomic_filtered, fit_reg=True)\n",
    "\n",
    "# Modify plot\n",
    "shapescatter.set(ylim=(0, 100), xlim = (0, 27000))\n",
    "shapescatter.set_ylabels('Tumor Maximum 3D Diameter (arb units)')\n",
    "shapescatter.set_xlabels('Tumor Volume (arb units)')\n",
    "\n",
    "#shapescatter.savefig(\"Volume_vs_3DDiamter.pdf\", bbox_inches='tight') # Uncomment to save "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Implementation \n",
    "Any function that can be set to a random state should be set to one to ensure reproduciblity. All print outputs are for debugging purposes. If one wishes to add or remove classifiers they should make the neccessary changes to the clf_list, parameters_list, and scores_list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 ANOVA features: score = 0.525\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 MI features: score = 0.45\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 CHI features: score = 0.55\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 ANOVA features: score = 0.475\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 MI features: score = 0.55\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 CHI features: score = 0.575\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 ANOVA features: score = 0.475\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 MI features: score = 0.525\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 CHI features: score = 0.575\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 ANOVA features: score = 0.55\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 MI features: score = 0.55\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 CHI features: score = 0.6\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 ANOVA features: score = 0.5\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 MI features: score = 0.375\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 CHI features: score = 0.45\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 ANOVA features: score = 0.55\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 MI features: score = 0.375\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 CHI features: score = 0.4\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 ANOVA features: score = 0.45\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 MI features: score = 0.4\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 CHI features: score = 0.375\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 ANOVA features: score = 0.375\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 MI features: score = 0.35\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 CHI features: score = 0.4\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 ANOVA features: score = 0.675\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 MI features: score = 0.625\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 CHI features: score = 0.45\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 ANOVA features: score = 0.5\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 MI features: score = 0.55\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 CHI features: score = 0.525\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 ANOVA features: score = 0.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 MI features: score = 0.625\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 CHI features: score = 0.65\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 ANOVA features: score = 0.55\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 MI features: score = 0.525\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 CHI features: score = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kareemwahid/anaconda/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 ANOVA features: score = 0.55\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 MI features: score = 0.5\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 CHI features: score = 0.55\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 ANOVA features: score = 0.5\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 MI features: score = 0.5\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 CHI features: score = 0.5\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 ANOVA features: score = 0.425\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 MI features: score = 0.525\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 CHI features: score = 0.475\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 ANOVA features: score = 0.425\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 MI features: score = 0.55\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 CHI features: score = 0.55\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 ANOVA features: score = 0.525\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 MI features: score = 0.55\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 CHI features: score = 0.55\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 ANOVA features: score = 0.55\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 MI features: score = 0.525\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 CHI features: score = 0.55\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 ANOVA features: score = 0.5\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 MI features: score = 0.65\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 CHI features: score = 0.575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 ANOVA features: score = 0.55\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 MI features: score = 0.75\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 CHI features: score = 0.575\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 ANOVA features: score = 0.5\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 MI features: score = 0.525\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 CHI features: score = 0.625\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=1, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 ANOVA features: score = 0.5\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=1, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 MI features: score = 0.475\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 CHI features: score = 0.65\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 ANOVA features: score = 0.575\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 MI features: score = 0.5\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 CHI features: score = 0.525\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 ANOVA features: score = 0.525\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 MI features: score = 0.65\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 CHI features: score = 0.525\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 ANOVA features: score = 0.55\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 MI features: score = 0.5\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 CHI features: score = 0.55\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 ANOVA features: score = 0.525\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 MI features: score = 0.525\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 CHI features: score = 0.525\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 ANOVA features: score = 0.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 MI features: score = 0.575\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 CHI features: score = 0.5\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 ANOVA features: score = 0.425\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 MI features: score = 0.575\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 CHI features: score = 0.525\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 ANOVA features: score = 0.55\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 MI features: score = 0.5\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 CHI features: score = 0.55\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 ANOVA features: score = 0.525\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 MI features: score = 0.525\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 CHI features: score = 0.525\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 ANOVA features: score = 0.425\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 MI features: score = 0.55\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 CHI features: score = 0.5\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 ANOVA features: score = 0.45\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 MI features: score = 0.475\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 CHI features: score = 0.45\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 ANOVA features: score = 0.5\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 MI features: score = 0.5\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 CHI features: score = 0.475\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 ANOVA features: score = 0.575\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 MI features: score = 0.4\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 CHI features: score = 0.425\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 ANOVA features: score = 0.5\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 MI features: score = 0.4\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 CHI features: score = 0.475\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 ANOVA features: score = 0.475\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 MI features: score = 0.575\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 CHI features: score = 0.525\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 ANOVA features: score = 0.475\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 MI features: score = 0.6\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 CHI features: score = 0.45\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 ANOVA features: score = 0.65\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 MI features: score = 0.425\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 CHI features: score = 0.55\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 ANOVA features: score = 0.65\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 MI features: score = 0.45\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 CHI features: score = 0.575\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 ANOVA features: score = 0.575\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 MI features: score = 0.475\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 CHI features: score = 0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kareemwahid/anaconda/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 ANOVA features: score = 0.569444444444\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 MI features: score = 0.638888888889\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 CHI features: score = 0.625\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 ANOVA features: score = 0.611111111111\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 MI features: score = 0.680555555556\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 CHI features: score = 0.652777777778\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 ANOVA features: score = 0.680555555556\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 MI features: score = 0.694444444444\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 CHI features: score = 0.652777777778\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 ANOVA features: score = 0.694444444444\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 MI features: score = 0.722222222222\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 CHI features: score = 0.680555555556\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 ANOVA features: score = 0.583333333333\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 MI features: score = 0.513888888889\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 CHI features: score = 0.472222222222\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 ANOVA features: score = 0.569444444444\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 MI features: score = 0.541666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 CHI features: score = 0.5\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 ANOVA features: score = 0.597222222222\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 MI features: score = 0.5\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 CHI features: score = 0.5\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 ANOVA features: score = 0.5\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 MI features: score = 0.541666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 CHI features: score = 0.5\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 ANOVA features: score = 0.555555555556\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 MI features: score = 0.569444444444\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 CHI features: score = 0.597222222222\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 ANOVA features: score = 0.652777777778\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 MI features: score = 0.652777777778\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 CHI features: score = 0.680555555556\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 ANOVA features: score = 0.694444444444\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 MI features: score = 0.652777777778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 CHI features: score = 0.680555555556\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 ANOVA features: score = 0.680555555556\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 MI features: score = 0.680555555556\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 CHI features: score = 0.680555555556\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 ANOVA features: score = 0.597222222222\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 MI features: score = 0.5\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 CHI features: score = 0.569444444444\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 ANOVA features: score = 0.652777777778\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 MI features: score = 0.527777777778\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 CHI features: score = 0.541666666667\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 ANOVA features: score = 0.569444444444\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 MI features: score = 0.5\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 CHI features: score = 0.569444444444\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(1,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 ANOVA features: score = 0.569444444444\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 MI features: score = 0.541666666667\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(1,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 CHI features: score = 0.652777777778\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 ANOVA features: score = 0.513888888889\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 MI features: score = 0.486111111111\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 CHI features: score = 0.583333333333\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 ANOVA features: score = 0.736111111111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 MI features: score = 0.736111111111\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 CHI features: score = 0.736111111111\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 ANOVA features: score = 0.722222222222\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 MI features: score = 0.680555555556\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 CHI features: score = 0.625\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 ANOVA features: score = 0.694444444444\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 MI features: score = 0.763888888889\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 CHI features: score = 0.736111111111\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 ANOVA features: score = 0.5\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 MI features: score = 0.597222222222\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 CHI features: score = 0.569444444444\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 ANOVA features: score = 0.708333333333\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=1, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 MI features: score = 0.652777777778\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 CHI features: score = 0.708333333333\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 ANOVA features: score = 0.680555555556\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=1, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 MI features: score = 0.652777777778\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 CHI features: score = 0.694444444444\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=1, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 ANOVA features: score = 0.625\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 MI features: score = 0.638888888889\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 CHI features: score = 0.736111111111\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 ANOVA features: score = 0.569444444444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 MI features: score = 0.458333333333\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 CHI features: score = 0.569444444444\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 ANOVA features: score = 0.569444444444\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 MI features: score = 0.527777777778\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 CHI features: score = 0.569444444444\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 ANOVA features: score = 0.569444444444\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 MI features: score = 0.527777777778\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 CHI features: score = 0.569444444444\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 ANOVA features: score = 0.569444444444\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 MI features: score = 0.555555555556\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 CHI features: score = 0.569444444444\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 ANOVA features: score = 0.541666666667\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 MI features: score = 0.569444444444\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 CHI features: score = 0.541666666667\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 ANOVA features: score = 0.597222222222\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 MI features: score = 0.513888888889\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 CHI features: score = 0.569444444444\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 ANOVA features: score = 0.597222222222\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 MI features: score = 0.486111111111\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 CHI features: score = 0.555555555556\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 ANOVA features: score = 0.569444444444\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 MI features: score = 0.486111111111\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 CHI features: score = 0.555555555556\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 ANOVA features: score = 0.611111111111\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 MI features: score = 0.486111111111\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 CHI features: score = 0.597222222222\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 ANOVA features: score = 0.680555555556\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 MI features: score = 0.555555555556\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 CHI features: score = 0.625\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 ANOVA features: score = 0.722222222222\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 MI features: score = 0.486111111111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 CHI features: score = 0.652777777778\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 ANOVA features: score = 0.638888888889\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 MI features: score = 0.638888888889\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 CHI features: score = 0.569444444444\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 ANOVA features: score = 0.611111111111\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 MI features: score = 0.458333333333\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 CHI features: score = 0.569444444444\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 ANOVA features: score = 0.625\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 MI features: score = 0.597222222222\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 CHI features: score = 0.638888888889\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 ANOVA features: score = 0.638888888889\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 MI features: score = 0.5\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 CHI features: score = 0.597222222222\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 ANOVA features: score = 0.625\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 MI features: score = 0.583333333333\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 CHI features: score = 0.527777777778\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 ANOVA features: score = 0.625\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 MI features: score = 0.694444444444\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 CHI features: score = 0.625\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 ANOVA features: score = 0.666666666667\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 MI features: score = 0.472222222222\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 CHI features: score = 0.652777777778\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 ANOVA features: score = 0.666666666667\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 MI features: score = 0.652777777778\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 CHI features: score = 0.666666666667\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 ANOVA features: score = 0.666666666667\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 MI features: score = 0.694444444444\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 40 CHI features: score = 0.666666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 ANOVA features: score = 0.597222222222\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 MI features: score = 0.416666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 CHI features: score = 0.5\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 ANOVA features: score = 0.555555555556\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 MI features: score = 0.458333333333\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 CHI features: score = 0.5\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 ANOVA features: score = 0.472222222222\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 MI features: score = 0.472222222222\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 CHI features: score = 0.5\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 ANOVA features: score = 0.5\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 MI features: score = 0.444444444444\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 CHI features: score = 0.5\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 ANOVA features: score = 0.472222222222\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 MI features: score = 0.680555555556\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 CHI features: score = 0.569444444444\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 ANOVA features: score = 0.722222222222\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 MI features: score = 0.527777777778\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 CHI features: score = 0.680555555556\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 ANOVA features: score = 0.569444444444\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 MI features: score = 0.763888888889\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 CHI features: score = 0.680555555556\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 ANOVA features: score = 0.611111111111\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 MI features: score = 0.763888888889\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 CHI features: score = 0.569444444444\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 ANOVA features: score = 0.527777777778\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 MI features: score = 0.611111111111\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 CHI features: score = 0.625\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 ANOVA features: score = 0.555555555556\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 MI features: score = 0.569444444444\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 CHI features: score = 0.597222222222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 ANOVA features: score = 0.597222222222\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 MI features: score = 0.597222222222\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 CHI features: score = 0.638888888889\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 ANOVA features: score = 0.555555555556\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 MI features: score = 0.597222222222\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 CHI features: score = 0.597222222222\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 ANOVA features: score = 0.763888888889\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 MI features: score = 0.694444444444\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 CHI features: score = 0.666666666667\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 ANOVA features: score = 0.763888888889\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 MI features: score = 0.638888888889\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 CHI features: score = 0.611111111111\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 ANOVA features: score = 0.666666666667\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 MI features: score = 0.666666666667\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 CHI features: score = 0.694444444444\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 ANOVA features: score = 0.652777777778\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 MI features: score = 0.736111111111\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 CHI features: score = 0.666666666667\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 ANOVA features: score = 0.611111111111\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 MI features: score = 0.638888888889\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 CHI features: score = 0.680555555556\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 ANOVA features: score = 0.583333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 MI features: score = 0.666666666667\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 CHI features: score = 0.638888888889\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 ANOVA features: score = 0.638888888889\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 MI features: score = 0.611111111111\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 CHI features: score = 0.625\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 ANOVA features: score = 0.611111111111\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 MI features: score = 0.694444444444\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 CHI features: score = 0.680555555556\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 ANOVA features: score = 0.555555555556\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 MI features: score = 0.625\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 CHI features: score = 0.625\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 ANOVA features: score = 0.597222222222\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 MI features: score = 0.597222222222\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 CHI features: score = 0.555555555556\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 ANOVA features: score = 0.638888888889\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 MI features: score = 0.555555555556\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 CHI features: score = 0.597222222222\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 ANOVA features: score = 0.638888888889\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 MI features: score = 0.555555555556\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 CHI features: score = 0.555555555556\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 ANOVA features: score = 0.597222222222\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 MI features: score = 0.541666666667\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 CHI features: score = 0.597222222222\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 ANOVA features: score = 0.597222222222\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 MI features: score = 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 CHI features: score = 0.638888888889\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 ANOVA features: score = 0.597222222222\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 MI features: score = 0.597222222222\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 CHI features: score = 0.597222222222\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 ANOVA features: score = 0.597222222222\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 MI features: score = 0.597222222222\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 CHI features: score = 0.597222222222\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 ANOVA features: score = 0.569444444444\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 MI features: score = 0.611111111111\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 CHI features: score = 0.652777777778\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 ANOVA features: score = 0.638888888889\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 MI features: score = 0.527777777778\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 CHI features: score = 0.611111111111\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 ANOVA features: score = 0.555555555556\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 MI features: score = 0.638888888889\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 CHI features: score = 0.569444444444\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 ANOVA features: score = 0.583333333333\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 MI features: score = 0.583333333333\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 CHI features: score = 0.597222222222\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 ANOVA features: score = 0.486111111111\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 MI features: score = 0.458333333333\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 CHI features: score = 0.472222222222\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 ANOVA features: score = 0.486111111111\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 MI features: score = 0.611111111111\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 CHI features: score = 0.541666666667\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 ANOVA features: score = 0.388888888889\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 MI features: score = 0.527777777778\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 CHI features: score = 0.444444444444\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 ANOVA features: score = 0.416666666667\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 MI features: score = 0.652777777778\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 CHI features: score = 0.333333333333\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 ANOVA features: score = 0.727678571429\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 MI features: score = 0.620535714286\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 10 CHI features: score = 0.696428571429\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 ANOVA features: score = 0.669642857143\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 MI features: score = 0.59375\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 CHI features: score = 0.763392857143\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 ANOVA features: score = 0.65625\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 MI features: score = 0.589285714286\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 CHI features: score = 0.732142857143\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 ANOVA features: score = 0.6875\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 MI features: score = 0.691964285714\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 CHI features: score = 0.763392857143\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 ANOVA features: score = 0.691964285714\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 MI features: score = 0.566964285714\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 CHI features: score = 0.464285714286\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 ANOVA features: score = 0.455357142857\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 MI features: score = 0.508928571429\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 CHI features: score = 0.428571428571\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 ANOVA features: score = 0.491071428571\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 MI features: score = 0.424107142857\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 CHI features: score = 0.392857142857\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 ANOVA features: score = 0.53125\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 MI features: score = 0.424107142857\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 CHI features: score = 0.455357142857\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 ANOVA features: score = 0.669642857143\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 MI features: score = 0.625\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 CHI features: score = 0.638392857143\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 ANOVA features: score = 0.59375\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 MI features: score = 0.598214285714\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 CHI features: score = 0.638392857143\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 ANOVA features: score = 0.665178571429\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 MI features: score = 0.602678571429\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 CHI features: score = 0.665178571429\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 ANOVA features: score = 0.691964285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 MI features: score = 0.544642857143\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 CHI features: score = 0.558035714286\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 ANOVA features: score = 0.660714285714\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 MI features: score = 0.450892857143\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 CHI features: score = 0.660714285714\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 ANOVA features: score = 0.625\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 MI features: score = 0.558035714286\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 CHI features: score = 0.589285714286\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 ANOVA features: score = 0.629464285714\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 MI features: score = 0.53125\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 CHI features: score = 0.558035714286\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 ANOVA features: score = 0.660714285714\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 MI features: score = 0.59375\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 CHI features: score = 0.491071428571\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 ANOVA features: score = 0.723214285714\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 MI features: score = 0.6875\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 CHI features: score = 0.794642857143\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 ANOVA features: score = 0.696428571429\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 MI features: score = 0.696428571429\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 CHI features: score = 0.830357142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 ANOVA features: score = 0.727678571429\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 MI features: score = 0.620535714286\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 CHI features: score = 0.830357142857\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 ANOVA features: score = 0.727678571429\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 MI features: score = 0.727678571429\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 CHI features: score = 0.799107142857\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 ANOVA features: score = 0.799107142857\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 MI features: score = 0.723214285714\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=1, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 CHI features: score = 0.602678571429\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 ANOVA features: score = 0.665178571429\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 MI features: score = 0.598214285714\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 CHI features: score = 0.700892857143\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 ANOVA features: score = 0.758928571429\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 MI features: score = 0.526785714286\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 CHI features: score = 0.700892857143\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 ANOVA features: score = 0.629464285714\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 MI features: score = 0.629464285714\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 CHI features: score = 0.763392857143\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 ANOVA features: score = 0.691964285714\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 MI features: score = 0.482142857143\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 CHI features: score = 0.660714285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 ANOVA features: score = 0.620535714286\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 MI features: score = 0.482142857143\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 CHI features: score = 0.620535714286\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 ANOVA features: score = 0.620535714286\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 MI features: score = 0.482142857143\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 CHI features: score = 0.620535714286\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 ANOVA features: score = 0.620535714286\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 MI features: score = 0.553571428571\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 CHI features: score = 0.65625\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 ANOVA features: score = 0.660714285714\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 MI features: score = 0.455357142857\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 CHI features: score = 0.660714285714\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 ANOVA features: score = 0.589285714286\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 MI features: score = 0.464285714286\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 CHI features: score = 0.625\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 ANOVA features: score = 0.625\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 MI features: score = 0.46875\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 CHI features: score = 0.526785714286\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 ANOVA features: score = 0.589285714286\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 MI features: score = 0.59375\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 CHI features: score = 0.589285714286\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 ANOVA features: score = 0.65625\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 MI features: score = 0.5625\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 CHI features: score = 0.633928571429\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 ANOVA features: score = 0.65625\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 MI features: score = 0.5\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 CHI features: score = 0.620535714286\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 ANOVA features: score = 0.589285714286\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 MI features: score = 0.517857142857\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 CHI features: score = 0.59375\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 ANOVA features: score = 0.522321428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 MI features: score = 0.491071428571\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 CHI features: score = 0.59375\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 ANOVA features: score = 0.598214285714\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 MI features: score = 0.566964285714\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 CHI features: score = 0.415178571429\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 ANOVA features: score = 0.5625\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 MI features: score = 0.629464285714\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 CHI features: score = 0.540178571429\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 ANOVA features: score = 0.464285714286\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 MI features: score = 0.633928571429\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 CHI features: score = 0.526785714286\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 ANOVA features: score = 0.566964285714\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 MI features: score = 0.508928571429\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 CHI features: score = 0.495535714286\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 ANOVA features: score = 0.5\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 MI features: score = 0.517857142857\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 CHI features: score = 0.491071428571\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 ANOVA features: score = 0.571428571429\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 MI features: score = 0.633928571429\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 CHI features: score = 0.5\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 ANOVA features: score = 0.535714285714\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 MI features: score = 0.589285714286\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 CHI features: score = 0.5\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 ANOVA features: score = 0.571428571429\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 MI features: score = 0.665178571429\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 CHI features: score = 0.535714285714\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 ANOVA features: score = 0.428571428571\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 MI features: score = 0.535714285714\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 CHI features: score = 0.535714285714\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 ANOVA features: score = 0.575892857143\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 MI features: score = 0.540178571429\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 CHI features: score = 0.535714285714\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 ANOVA features: score = 0.584821428571\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 MI features: score = 0.535714285714\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 CHI features: score = 0.535714285714\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 ANOVA features: score = 0.46875\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 MI features: score = 0.535714285714\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 CHI features: score = 0.535714285714\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 ANOVA features: score = 0.625\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 MI features: score = 0.526785714286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 CHI features: score = 0.513392857143\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 ANOVA features: score = 0.625\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 MI features: score = 0.620535714286\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 CHI features: score = 0.59375\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 ANOVA features: score = 0.598214285714\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 MI features: score = 0.558035714286\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 CHI features: score = 0.629464285714\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 ANOVA features: score = 0.397321428571\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 MI features: score = 0.535714285714\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 CHI features: score = 0.491071428571\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 ANOVA features: score = 0.459821428571\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 MI features: score = 0.616071428571\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 CHI features: score = 0.464285714286\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 ANOVA features: score = 0.46875\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 MI features: score = 0.491071428571\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 CHI features: score = 0.504464285714\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(1,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 ANOVA features: score = 0.397321428571\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 MI features: score = 0.428571428571\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 CHI features: score = 0.46875\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(1,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 ANOVA features: score = 0.549107142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 MI features: score = 0.433035714286\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 CHI features: score = 0.455357142857\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 ANOVA features: score = 0.46875\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 MI features: score = 0.495535714286\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 CHI features: score = 0.53125\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 ANOVA features: score = 0.558035714286\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 MI features: score = 0.5625\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 CHI features: score = 0.504464285714\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 ANOVA features: score = 0.535714285714\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 MI features: score = 0.598214285714\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 CHI features: score = 0.535714285714\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 ANOVA features: score = 0.638392857143\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 MI features: score = 0.665178571429\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 CHI features: score = 0.607142857143\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 ANOVA features: score = 0.392857142857\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 MI features: score = 0.491071428571\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 CHI features: score = 0.5625\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 ANOVA features: score = 0.526785714286\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 MI features: score = 0.53125\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 CHI features: score = 0.665178571429\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 ANOVA features: score = 0.629464285714\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 MI features: score = 0.522321428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 CHI features: score = 0.540178571429\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 ANOVA features: score = 0.625\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 MI features: score = 0.633928571429\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=1, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 CHI features: score = 0.625\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 ANOVA features: score = 0.459821428571\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 MI features: score = 0.633928571429\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 CHI features: score = 0.459821428571\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 ANOVA features: score = 0.5\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 MI features: score = 0.508928571429\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 CHI features: score = 0.428571428571\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 ANOVA features: score = 0.5\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 MI features: score = 0.464285714286\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 CHI features: score = 0.459821428571\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 ANOVA features: score = 0.464285714286\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 MI features: score = 0.459821428571\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 CHI features: score = 0.433035714286\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 ANOVA features: score = 0.495535714286\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 MI features: score = 0.683035714286\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 CHI features: score = 0.495535714286\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 ANOVA features: score = 0.433035714286\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 MI features: score = 0.5625\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 CHI features: score = 0.464285714286\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 ANOVA features: score = 0.46875\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 MI features: score = 0.464285714286\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 CHI features: score = 0.433035714286\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 ANOVA features: score = 0.504464285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 MI features: score = 0.5\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 CHI features: score = 0.46875\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 ANOVA features: score = 0.495535714286\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 MI features: score = 0.566964285714\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 CHI features: score = 0.428571428571\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 ANOVA features: score = 0.589285714286\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 MI features: score = 0.5\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 CHI features: score = 0.566964285714\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 ANOVA features: score = 0.625\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 MI features: score = 0.459821428571\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 CHI features: score = 0.53125\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 ANOVA features: score = 0.459821428571\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 MI features: score = 0.459821428571\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 CHI features: score = 0.459821428571\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 ANOVA features: score = 0.558035714286\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 MI features: score = 0.571428571429\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 CHI features: score = 0.553571428571\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 ANOVA features: score = 0.34375\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 MI features: score = 0.352678571429\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 CHI features: score = 0.455357142857\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 ANOVA features: score = 0.401785714286\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 MI features: score = 0.392857142857\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 CHI features: score = 0.482142857143\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 ANOVA features: score = 0.419642857143\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 MI features: score = 0.486607142857\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 CHI features: score = 0.392857142857\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 ANOVA features: score = 0.53125\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 MI features: score = 0.59375\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 CHI features: score = 0.736607142857\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 ANOVA features: score = 0.526785714286\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 MI features: score = 0.665178571429\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 CHI features: score = 0.660714285714\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 30 ANOVA features: score = 0.660714285714\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 MI features: score = 0.660714285714\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 CHI features: score = 0.660714285714\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 ANOVA features: score = 0.65625\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 MI features: score = 0.660714285714\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 CHI features: score = 0.59375\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 ANOVA features: score = 0.415178571429\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 MI features: score = 0.491071428571\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 CHI features: score = 0.424107142857\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 ANOVA features: score = 0.455357142857\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 MI features: score = 0.482142857143\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 CHI features: score = 0.424107142857\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 ANOVA features: score = 0.459821428571\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 MI features: score = 0.491071428571\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 CHI features: score = 0.455357142857\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 ANOVA features: score = 0.4375\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 MI features: score = 0.455357142857\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 CHI features: score = 0.455357142857\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 ANOVA features: score = 0.508928571429\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 MI features: score = 0.526785714286\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 CHI features: score = 0.674107142857\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 ANOVA features: score = 0.566964285714\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 MI features: score = 0.566964285714\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 CHI features: score = 0.366071428571\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 ANOVA features: score = 0.633928571429\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 MI features: score = 0.53125\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 CHI features: score = 0.696428571429\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 ANOVA features: score = 0.5\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 MI features: score = 0.535714285714\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 CHI features: score = 0.5\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 ANOVA features: score = 0.65625\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 MI features: score = 0.553571428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 CHI features: score = 0.691964285714\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 ANOVA features: score = 0.5625\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 MI features: score = 0.607142857143\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 CHI features: score = 0.5625\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 ANOVA features: score = 0.665178571429\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(1,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 MI features: score = 0.535714285714\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 CHI features: score = 0.660714285714\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 ANOVA features: score = 0.638392857143\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 MI features: score = 0.598214285714\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 CHI features: score = 0.629464285714\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 ANOVA features: score = 0.535714285714\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 MI features: score = 0.5625\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 CHI features: score = 0.700892857143\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 ANOVA features: score = 0.526785714286\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 MI features: score = 0.59375\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 CHI features: score = 0.669642857143\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 ANOVA features: score = 0.558035714286\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 MI features: score = 0.504464285714\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 CHI features: score = 0.638392857143\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 ANOVA features: score = 0.589285714286\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 MI features: score = 0.397321428571\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 CHI features: score = 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 ANOVA features: score = 0.571428571429\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 MI features: score = 0.5625\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 CHI features: score = 0.803571428571\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 ANOVA features: score = 0.598214285714\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 MI features: score = 0.566964285714\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 CHI features: score = 0.705357142857\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 ANOVA features: score = 0.629464285714\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 MI features: score = 0.598214285714\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 CHI features: score = 0.700892857143\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 ANOVA features: score = 0.633928571429\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 MI features: score = 0.625\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 CHI features: score = 0.700892857143\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 ANOVA features: score = 0.727678571429\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 MI features: score = 0.660714285714\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 CHI features: score = 0.763392857143\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 ANOVA features: score = 0.660714285714\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 MI features: score = 0.660714285714\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 CHI features: score = 0.763392857143\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 ANOVA features: score = 0.665178571429\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 MI features: score = 0.696428571429\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 CHI features: score = 0.696428571429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 ANOVA features: score = 0.665178571429\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 MI features: score = 0.696428571429\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 CHI features: score = 0.696428571429\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 ANOVA features: score = 0.700892857143\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 MI features: score = 0.5625\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 CHI features: score = 0.723214285714\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 ANOVA features: score = 0.602678571429\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 MI features: score = 0.598214285714\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 CHI features: score = 0.763392857143\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 ANOVA features: score = 0.598214285714\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 MI features: score = 0.625\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 CHI features: score = 0.571428571429\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 ANOVA features: score = 0.504464285714\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 MI features: score = 0.660714285714\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 CHI features: score = 0.607142857143\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 ANOVA features: score = 0.59375\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 MI features: score = 0.59375\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 CHI features: score = 0.691964285714\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 ANOVA features: score = 0.598214285714\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 MI features: score = 0.522321428571\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 CHI features: score = 0.486607142857\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 ANOVA features: score = 0.455357142857\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 MI features: score = 0.65625\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 CHI features: score = 0.464285714286\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 ANOVA features: score = 0.598214285714\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 MI features: score = 0.620535714286\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 CHI features: score = 0.59375\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 ANOVA features: score = 0.522321428571\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 MI features: score = 0.522321428571\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 CHI features: score = 0.455357142857\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 ANOVA features: score = 0.526785714286\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 MI features: score = 0.482142857143\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 CHI features: score = 0.459821428571\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 ANOVA features: score = 0.450892857143\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 MI features: score = 0.40625\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 CHI features: score = 0.540178571429\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 ANOVA features: score = 0.455357142857\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 MI features: score = 0.40625\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 CHI features: score = 0.415178571429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 ANOVA features: score = 0.65\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 MI features: score = 0.55\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 CHI features: score = 0.575\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 ANOVA features: score = 0.625\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 MI features: score = 0.525\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 CHI features: score = 0.65\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 ANOVA features: score = 0.5\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 MI features: score = 0.525\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 CHI features: score = 0.45\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 ANOVA features: score = 0.45\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 MI features: score = 0.525\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 CHI features: score = 0.525\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 ANOVA features: score = 0.625\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 MI features: score = 0.275\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 CHI features: score = 0.6\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 ANOVA features: score = 0.6\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 MI features: score = 0.3\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 CHI features: score = 0.725\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 ANOVA features: score = 0.625\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 MI features: score = 0.275\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 CHI features: score = 0.65\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 ANOVA features: score = 0.725\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 MI features: score = 0.275\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 CHI features: score = 0.6\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 ANOVA features: score = 0.7\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 MI features: score = 0.525\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 CHI features: score = 0.525\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 ANOVA features: score = 0.525\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 MI features: score = 0.625\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 CHI features: score = 0.475\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 ANOVA features: score = 0.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 MI features: score = 0.425\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 CHI features: score = 0.575\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 ANOVA features: score = 0.5\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 MI features: score = 0.475\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 CHI features: score = 0.5\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 ANOVA features: score = 0.55\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 MI features: score = 0.625\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 CHI features: score = 0.6\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 ANOVA features: score = 0.55\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 MI features: score = 0.45\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 CHI features: score = 0.7\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 ANOVA features: score = 0.525\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 MI features: score = 0.45\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 CHI features: score = 0.55\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 ANOVA features: score = 0.575\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 MI features: score = 0.375\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 CHI features: score = 0.6\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 ANOVA features: score = 0.65\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 MI features: score = 0.55\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 CHI features: score = 0.575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 ANOVA features: score = 0.55\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 MI features: score = 0.7\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 CHI features: score = 0.225\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 ANOVA features: score = 0.45\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 MI features: score = 0.6\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 CHI features: score = 0.475\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 ANOVA features: score = 0.55\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 MI features: score = 0.575\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 CHI features: score = 0.5\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 ANOVA features: score = 0.625\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 MI features: score = 0.575\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 CHI features: score = 0.65\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 ANOVA features: score = 0.6\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 MI features: score = 0.75\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 CHI features: score = 0.75\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 ANOVA features: score = 0.55\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 MI features: score = 0.65\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 CHI features: score = 0.6\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 ANOVA features: score = 0.525\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 MI features: score = 0.55\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 CHI features: score = 0.55\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 ANOVA features: score = 0.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 MI features: score = 0.5\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 CHI features: score = 0.55\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 ANOVA features: score = 0.6\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 MI features: score = 0.525\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 CHI features: score = 0.525\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 ANOVA features: score = 0.525\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 MI features: score = 0.5\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 CHI features: score = 0.45\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 ANOVA features: score = 0.525\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 MI features: score = 0.5\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 CHI features: score = 0.475\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 ANOVA features: score = 0.525\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 MI features: score = 0.575\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 CHI features: score = 0.55\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 ANOVA features: score = 0.5\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 MI features: score = 0.525\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 CHI features: score = 0.625\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 ANOVA features: score = 0.525\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 MI features: score = 0.45\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 CHI features: score = 0.525\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 ANOVA features: score = 0.575\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 MI features: score = 0.4\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 CHI features: score = 0.55\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 ANOVA features: score = 0.6\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 MI features: score = 0.45\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 CHI features: score = 0.675\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 ANOVA features: score = 0.575\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 MI features: score = 0.45\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 CHI features: score = 0.5\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 ANOVA features: score = 0.475\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 MI features: score = 0.45\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 CHI features: score = 0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 ANOVA features: score = 0.375\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 MI features: score = 0.5\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 CHI features: score = 0.35\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 ANOVA features: score = 0.425\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 MI features: score = 0.4\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 CHI features: score = 0.45\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 ANOVA features: score = 0.5\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 MI features: score = 0.35\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 CHI features: score = 0.625\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 ANOVA features: score = 0.55\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 MI features: score = 0.275\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 CHI features: score = 0.45\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 ANOVA features: score = 0.625\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 MI features: score = 0.275\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 CHI features: score = 0.425\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 ANOVA features: score = 0.633333333333\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 MI features: score = 0.6\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 CHI features: score = 0.566666666667\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 ANOVA features: score = 0.633333333333\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 MI features: score = 0.6\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 CHI features: score = 0.6\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 ANOVA features: score = 0.666666666667\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 MI features: score = 0.6\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 CHI features: score = 0.633333333333\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 ANOVA features: score = 0.6\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 MI features: score = 0.6\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 CHI features: score = 0.633333333333\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 ANOVA features: score = 0.6\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 MI features: score = 0.466666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 CHI features: score = 0.466666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 ANOVA features: score = 0.566666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 MI features: score = 0.466666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 CHI features: score = 0.633333333333\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 ANOVA features: score = 0.5\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 MI features: score = 0.466666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 CHI features: score = 0.566666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 ANOVA features: score = 0.566666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 MI features: score = 0.433333333333\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 CHI features: score = 0.6\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 ANOVA features: score = 0.633333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 MI features: score = 0.533333333333\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 CHI features: score = 0.666666666667\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 ANOVA features: score = 0.533333333333\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 MI features: score = 0.633333333333\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 CHI features: score = 0.6\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 ANOVA features: score = 0.566666666667\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 MI features: score = 0.466666666667\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 CHI features: score = 0.6\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 ANOVA features: score = 0.533333333333\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 MI features: score = 0.6\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 CHI features: score = 0.533333333333\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 ANOVA features: score = 0.6\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 MI features: score = 0.566666666667\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 CHI features: score = 0.633333333333\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 ANOVA features: score = 0.533333333333\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 MI features: score = 0.6\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 CHI features: score = 0.633333333333\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 ANOVA features: score = 0.6\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 MI features: score = 0.6\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 CHI features: score = 0.566666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 ANOVA features: score = 0.566666666667\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 MI features: score = 0.466666666667\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 CHI features: score = 0.566666666667\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 ANOVA features: score = 0.533333333333\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 MI features: score = 0.5\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 CHI features: score = 0.566666666667\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 ANOVA features: score = 0.566666666667\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 MI features: score = 0.533333333333\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 CHI features: score = 0.633333333333\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 ANOVA features: score = 0.533333333333\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 MI features: score = 0.7\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 CHI features: score = 0.566666666667\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 ANOVA features: score = 0.533333333333\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 MI features: score = 0.666666666667\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 CHI features: score = 0.5\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 ANOVA features: score = 0.633333333333\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 MI features: score = 0.466666666667\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 CHI features: score = 0.633333333333\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 ANOVA features: score = 0.6\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 MI features: score = 0.566666666667\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 CHI features: score = 0.6\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 ANOVA features: score = 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 MI features: score = 0.433333333333\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 CHI features: score = 0.6\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 ANOVA features: score = 0.666666666667\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 MI features: score = 0.5\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 CHI features: score = 0.6\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 ANOVA features: score = 0.633333333333\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 MI features: score = 0.466666666667\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 CHI features: score = 0.633333333333\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 ANOVA features: score = 0.6\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 MI features: score = 0.633333333333\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 CHI features: score = 0.633333333333\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 ANOVA features: score = 0.566666666667\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 MI features: score = 0.666666666667\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 CHI features: score = 0.6\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 ANOVA features: score = 0.6\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 MI features: score = 0.666666666667\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 CHI features: score = 0.6\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 ANOVA features: score = 0.6\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 MI features: score = 0.566666666667\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 CHI features: score = 0.566666666667\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 ANOVA features: score = 0.566666666667\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 MI features: score = 0.666666666667\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 CHI features: score = 0.633333333333\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 ANOVA features: score = 0.566666666667\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 MI features: score = 0.633333333333\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 CHI features: score = 0.633333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 ANOVA features: score = 0.633333333333\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 MI features: score = 0.6\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 CHI features: score = 0.633333333333\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 ANOVA features: score = 0.533333333333\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 MI features: score = 0.633333333333\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 CHI features: score = 0.666666666667\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 ANOVA features: score = 0.6\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 MI features: score = 0.533333333333\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 CHI features: score = 0.7\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 ANOVA features: score = 0.566666666667\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 MI features: score = 0.7\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 CHI features: score = 0.633333333333\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 ANOVA features: score = 0.5\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 MI features: score = 0.666666666667\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 CHI features: score = 0.6\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 ANOVA features: score = 0.5\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 MI features: score = 0.533333333333\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 CHI features: score = 0.5\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 ANOVA features: score = 0.466666666667\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 MI features: score = 0.5\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 CHI features: score = 0.5\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 ANOVA features: score = 0.566666666667\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 MI features: score = 0.466666666667\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 CHI features: score = 0.5\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 ANOVA features: score = 0.433333333333\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 MI features: score = 0.433333333333\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 CHI features: score = 0.5\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 ANOVA features: score = 0.466666666667\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 MI features: score = 0.633333333333\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 CHI features: score = 0.6\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 ANOVA features: score = 0.566666666667\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 MI features: score = 0.666666666667\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 20 CHI features: score = 0.566666666667\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 ANOVA features: score = 0.6\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 MI features: score = 0.666666666667\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 CHI features: score = 0.566666666667\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 ANOVA features: score = 0.566666666667\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 MI features: score = 0.633333333333\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 CHI features: score = 0.566666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 ANOVA features: score = 0.533333333333\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 MI features: score = 0.366666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 CHI features: score = 0.533333333333\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 ANOVA features: score = 0.466666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 MI features: score = 0.366666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 CHI features: score = 0.466666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 ANOVA features: score = 0.5\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 MI features: score = 0.4\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 CHI features: score = 0.5\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 ANOVA features: score = 0.5\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 MI features: score = 0.366666666667\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 CHI features: score = 0.5\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 ANOVA features: score = 0.533333333333\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 MI features: score = 0.7\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 CHI features: score = 0.466666666667\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 ANOVA features: score = 0.633333333333\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 MI features: score = 0.566666666667\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 CHI features: score = 0.633333333333\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 ANOVA features: score = 0.7\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 MI features: score = 0.466666666667\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 CHI features: score = 0.633333333333\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 ANOVA features: score = 0.666666666667\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 MI features: score = 0.466666666667\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 CHI features: score = 0.666666666667\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 ANOVA features: score = 0.566666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 MI features: score = 0.333333333333\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 CHI features: score = 0.466666666667\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 ANOVA features: score = 0.433333333333\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 MI features: score = 0.4\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 CHI features: score = 0.433333333333\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 ANOVA features: score = 0.533333333333\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 MI features: score = 0.4\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 CHI features: score = 0.5\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 ANOVA features: score = 0.533333333333\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(1,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 MI features: score = 0.566666666667\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 CHI features: score = 0.533333333333\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 ANOVA features: score = 0.433333333333\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 MI features: score = 0.6\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 CHI features: score = 0.633333333333\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 ANOVA features: score = 0.533333333333\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 MI features: score = 0.666666666667\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 CHI features: score = 0.533333333333\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 ANOVA features: score = 0.6\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 MI features: score = 0.6\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 CHI features: score = 0.533333333333\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 ANOVA features: score = 0.6\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 MI features: score = 0.566666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 CHI features: score = 0.6\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 ANOVA features: score = 0.466666666667\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 MI features: score = 0.6\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 CHI features: score = 0.566666666667\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 ANOVA features: score = 0.566666666667\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 MI features: score = 0.666666666667\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 CHI features: score = 0.566666666667\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 ANOVA features: score = 0.566666666667\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 MI features: score = 0.7\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 CHI features: score = 0.733333333333\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 ANOVA features: score = 0.566666666667\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 MI features: score = 0.666666666667\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 CHI features: score = 0.566666666667\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 ANOVA features: score = 0.533333333333\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 MI features: score = 0.366666666667\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 CHI features: score = 0.5\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 ANOVA features: score = 0.466666666667\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 MI features: score = 0.366666666667\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 CHI features: score = 0.466666666667\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 ANOVA features: score = 0.433333333333\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 MI features: score = 0.4\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 CHI features: score = 0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 ANOVA features: score = 0.433333333333\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 MI features: score = 0.433333333333\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 CHI features: score = 0.433333333333\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 ANOVA features: score = 0.5\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 MI features: score = 0.533333333333\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 CHI features: score = 0.433333333333\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 ANOVA features: score = 0.466666666667\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 MI features: score = 0.566666666667\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 CHI features: score = 0.466666666667\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 ANOVA features: score = 0.5\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 MI features: score = 0.566666666667\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 CHI features: score = 0.5\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 ANOVA features: score = 0.5\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 MI features: score = 0.433333333333\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 CHI features: score = 0.5\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 ANOVA features: score = 0.5\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 MI features: score = 0.5\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 CHI features: score = 0.5\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 ANOVA features: score = 0.6\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 MI features: score = 0.4\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 CHI features: score = 0.6\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 ANOVA features: score = 0.566666666667\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 MI features: score = 0.433333333333\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 CHI features: score = 0.566666666667\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 ANOVA features: score = 0.533333333333\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 MI features: score = 0.466666666667\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 CHI features: score = 0.533333333333\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 ANOVA features: score = 0.333333333333\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 MI features: score = 0.333333333333\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 CHI features: score = 0.5\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 ANOVA features: score = 0.5\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 MI features: score = 0.566666666667\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 CHI features: score = 0.5\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 ANOVA features: score = 0.466666666667\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 MI features: score = 0.433333333333\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 CHI features: score = 0.466666666667\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 ANOVA features: score = 0.666666666667\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 MI features: score = 0.566666666667\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 CHI features: score = 0.666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 ANOVA features: score = 0.590497737557\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 MI features: score = 0.70814479638\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 10 CHI features: score = 0.610859728507\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 ANOVA features: score = 0.649321266968\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 MI features: score = 0.746606334842\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 20 CHI features: score = 0.669683257919\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 ANOVA features: score = 0.68778280543\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 MI features: score = 0.746606334842\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 30 CHI features: score = 0.678733031674\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 ANOVA features: score = 0.68778280543\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 MI features: score = 0.669683257919\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False)\n",
      "RandomForestClassifier 40 CHI features: score = 0.649321266968\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 ANOVA features: score = 0.631221719457\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 MI features: score = 0.558823529412\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 10 CHI features: score = 0.549773755656\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 ANOVA features: score = 0.527149321267\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 MI features: score = 0.549773755656\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 20 CHI features: score = 0.529411764706\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 ANOVA features: score = 0.527149321267\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 MI features: score = 0.588235294118\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 30 CHI features: score = 0.52036199095\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 ANOVA features: score = 0.524886877828\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 MI features: score = 0.588235294118\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB 40 CHI features: score = 0.549773755656\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 ANOVA features: score = 0.542986425339\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 MI features: score = 0.601809954751\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 10 CHI features: score = 0.56334841629\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 ANOVA features: score = 0.619909502262\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 MI features: score = 0.613122171946\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 20 CHI features: score = 0.601809954751\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 ANOVA features: score = 0.649321266968\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 MI features: score = 0.454751131222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 30 CHI features: score = 0.671945701357\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 ANOVA features: score = 0.622171945701\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 MI features: score = 0.58371040724\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n",
      "DecisionTreeClassifier 40 CHI features: score = 0.613122171946\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 ANOVA features: score = 0.610859728507\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 MI features: score = 0.610859728507\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 10 CHI features: score = 0.513574660633\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.1,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 ANOVA features: score = 0.631221719457\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 MI features: score = 0.522624434389\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 20 CHI features: score = 0.581447963801\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 ANOVA features: score = 0.581447963801\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 MI features: score = 0.660633484163\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 30 CHI features: score = 0.552036199095\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.0001, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 ANOVA features: score = 0.522624434389\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 MI features: score = 0.542986425339\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=0, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "MLPClassifier 40 CHI features: score = 0.581447963801\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 ANOVA features: score = 0.610859728507\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 MI features: score = 0.678733031674\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 10 CHI features: score = 0.699095022624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 ANOVA features: score = 0.658371040724\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 MI features: score = 0.678733031674\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 20 CHI features: score = 0.610859728507\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 ANOVA features: score = 0.590497737557\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 MI features: score = 0.678733031674\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 30 CHI features: score = 0.649321266968\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 ANOVA features: score = 0.619909502262\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=5, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 MI features: score = 0.561085972851\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "BaggingClassifier 40 CHI features: score = 0.581447963801\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 ANOVA features: score = 0.658371040724\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 MI features: score = 0.658371040724\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 10 CHI features: score = 0.678733031674\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 ANOVA features: score = 0.658371040724\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 MI features: score = 0.572398190045\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 20 CHI features: score = 0.619909502262\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 ANOVA features: score = 0.68778280543\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 MI features: score = 0.572398190045\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 30 CHI features: score = 0.678733031674\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 ANOVA features: score = 0.649321266968\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 MI features: score = 0.640271493213\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "GradientBoostingClassifier 40 CHI features: score = 0.678733031674\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 ANOVA features: score = 0.5407239819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 MI features: score = 0.522624434389\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 10 CHI features: score = 0.542986425339\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 ANOVA features: score = 0.601809954751\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 MI features: score = 0.522624434389\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 20 CHI features: score = 0.610859728507\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 ANOVA features: score = 0.640271493213\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 MI features: score = 0.484162895928\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 30 CHI features: score = 0.640271493213\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 ANOVA features: score = 0.640271493213\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 MI features: score = 0.542986425339\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "SVC 40 CHI features: score = 0.640271493213\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 ANOVA features: score = 0.572398190045\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 MI features: score = 0.579185520362\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 10 CHI features: score = 0.513574660633\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 ANOVA features: score = 0.610859728507\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 MI features: score = 0.522624434389\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 20 CHI features: score = 0.599547511312\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 ANOVA features: score = 0.513574660633\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 MI features: score = 0.581447963801\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 30 CHI features: score = 0.542986425339\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 ANOVA features: score = 0.513574660633\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 MI features: score = 0.522624434389\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "LogisticRegression 40 CHI features: score = 0.522624434389\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 ANOVA features: score = 0.610859728507\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 MI features: score = 0.533936651584\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 10 CHI features: score = 0.581447963801\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 ANOVA features: score = 0.522624434389\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 MI features: score = 0.640271493213\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 20 CHI features: score = 0.649321266968\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 ANOVA features: score = 0.561085972851\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 MI features: score = 0.70814479638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 30 CHI features: score = 0.649321266968\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 ANOVA features: score = 0.561085972851\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 MI features: score = 0.678733031674\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "KNeighborsClassifier 40 CHI features: score = 0.561085972851\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 ANOVA features: score = 0.533936651584\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 MI features: score = 0.52036199095\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 10 CHI features: score = 0.524886877828\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 ANOVA features: score = 0.515837104072\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 MI features: score = 0.298642533937\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 20 CHI features: score = 0.622171945701\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 ANOVA features: score = 0.572398190045\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 MI features: score = 0.572398190045\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 30 CHI features: score = 0.447963800905\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 ANOVA features: score = 0.561085972851\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 MI features: score = 0.531674208145\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariances=False, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis 40 CHI features: score = 0.445701357466\n",
      "CPU times: user 1h 31min 11s, sys: 53.6 s, total: 1h 32min 4s\n",
      "Wall time: 1h 27min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "### Classifier intialization, all should be set to random state\n",
    "clf_A = RandomForestClassifier(random_state=0) \n",
    "clf_B = GaussianNB()\n",
    "clf_C = DecisionTreeClassifier(random_state=0)\n",
    "clf_D = MLPClassifier(random_state=0)\n",
    "clf_E = BaggingClassifier(random_state=0)\n",
    "clf_F = GradientBoostingClassifier(random_state=0)\n",
    "clf_G = SVC(random_state=0)\n",
    "clf_H = LogisticRegression(random_state=0)\n",
    "clf_I = KNeighborsClassifier()\n",
    "clf_J = QuadraticDiscriminantAnalysis()\n",
    "clf_list = [clf_A, clf_B, clf_C, clf_D, clf_E, clf_F, clf_G, clf_H, clf_I, clf_J]\n",
    "\n",
    "### Parameters to use for GridSearch\n",
    "parameters_A = {'min_samples_split':[2,20,30], 'n_estimators':[500]}\n",
    "parameters_B = None \n",
    "parameters_C = {'min_samples_split':[2,20,30]}\n",
    "parameters_D = {'hidden_layer_sizes':[(100,),(1,),(9,)],'beta_1':[0.9, 0.1, 0.0001]}\n",
    "parameters_E = {'n_estimators':[5,10,100]}\n",
    "parameters_F = {'n_estimators': [1,10,20,100]}\n",
    "parameters_G = {'C':[0.1,1.0,10.0], 'kernel':['poly', 'rbf']}\n",
    "parameters_H = {'C':[0.1,1.0,10.0], 'penalty':['l1','l2']}\n",
    "parameters_I = {'n_neighbors':[5,10,15,20]}\n",
    "parameters_J = None  \n",
    "\n",
    "parameters_list = [parameters_A, parameters_B, parameters_C, parameters_D, parameters_E, \n",
    "                   parameters_F, parameters_G, parameters_H, parameters_I, parameters_J]\n",
    "\n",
    "### Lists where scores will be stored for later analysis, Letter represents scoring function \n",
    "# A = ANOVA F-score, M = Mutual Information, C = Chi^2, numbers represent top number of features selected \n",
    "scores_A = {'A10':[], 'A20':[], 'A30':[], 'A40':[], 'M10':[], 'M20':[], 'M30':[], 'M40':[], 'C10':[], \n",
    "                     'C20':[], 'C30':[], 'C40':[]}\n",
    "scores_B = {'A10':[], 'A20':[], 'A30':[], 'A40':[], 'M10':[], 'M20':[], 'M30':[], 'M40':[], 'C10':[], \n",
    "                     'C20':[], 'C30':[], 'C40':[]}\n",
    "scores_C = {'A10':[], 'A20':[], 'A30':[], 'A40':[], 'M10':[], 'M20':[], 'M30':[], 'M40':[], 'C10':[], \n",
    "                     'C20':[], 'C30':[], 'C40':[]}\n",
    "scores_D = {'A10':[], 'A20':[], 'A30':[], 'A40':[], 'M10':[], 'M20':[], 'M30':[], 'M40':[], 'C10':[], \n",
    "                     'C20':[], 'C30':[], 'C40':[]}\n",
    "scores_E = {'A10':[], 'A20':[], 'A30':[], 'A40':[], 'M10':[], 'M20':[], 'M30':[], 'M40':[], 'C10':[], \n",
    "                     'C20':[], 'C30':[], 'C40':[]}\n",
    "scores_F = {'A10':[], 'A20':[], 'A30':[], 'A40':[], 'M10':[], 'M20':[], 'M30':[], 'M40':[], 'C10':[], \n",
    "                     'C20':[], 'C30':[], 'C40':[]}\n",
    "scores_G = {'A10':[], 'A20':[], 'A30':[], 'A40':[], 'M10':[], 'M20':[], 'M30':[], 'M40':[], 'C10':[], \n",
    "                     'C20':[], 'C30':[], 'C40':[]}\n",
    "scores_H = {'A10':[], 'A20':[], 'A30':[], 'A40':[], 'M10':[], 'M20':[], 'M30':[], 'M40':[], 'C10':[], \n",
    "                     'C20':[], 'C30':[], 'C40':[]}\n",
    "scores_I = {'A10':[], 'A20':[], 'A30':[], 'A40':[], 'M10':[], 'M20':[], 'M30':[], 'M40':[], 'C10':[], \n",
    "                     'C20':[], 'C30':[], 'C40':[]}\n",
    "scores_J = {'A10':[], 'A20':[], 'A30':[], 'A40':[], 'M10':[], 'M20':[], 'M30':[], 'M40':[], 'C10':[], \n",
    "                     'C20':[], 'C30':[], 'C40':[]}\n",
    "scores_list = [scores_A, scores_B, scores_C, scores_D, scores_E, scores_F, scores_G, scores_H, scores_I, scores_J]\n",
    "\n",
    "list_combined = zip(clf_list, parameters_list, scores_list) # Zip lists together for use below \n",
    "\n",
    "mutual_info_classif =  functools.partial(mutual_info_classif, random_state = 0) # Need to redefine to enable random_state\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 0) # Cross validation parameters for use in grid search\n",
    "\n",
    "for i in range(10): # Repeat the following 10 times, can change this to higher values but will slow computational time.\n",
    "    \n",
    "    # Split full dataset into train and test set \n",
    "    train, test = train_test_split(radiomic_filtered, test_size = 0.2, random_state=i) \n",
    "    survival_classes_train = train['Survival']  \n",
    "    features_train = train.drop('Survival', axis = 1)\n",
    "    survival_classes_test = test['Survival'] \n",
    "    features_test = test.drop('Survival', axis = 1)\n",
    "\n",
    "    # Normalizing features using z-score with respect to training set\n",
    "    scaler = MinMaxScaler().fit(features_train)\n",
    "    features_train_transformed = scaler.transform(features_train)\n",
    "    features_train_transformed = pd.DataFrame(features_train_transformed)\n",
    "    features_test_transformed = scaler.transform(features_test)\n",
    "    features_test_transformed = pd.DataFrame(features_test_transformed)\n",
    "\n",
    "    # Select top features using different feature numbers and feature selction methods and store in lists  \n",
    "    feature_number_list = [10,20,30,40]\n",
    "    score_func_list = [f_classif, mutual_info_classif, chi2]\n",
    "    features_train_transformed_selected_list =[]\n",
    "    features_test_transformed_selected_list =[]\n",
    "    for feature_number in feature_number_list:\n",
    "        for score_func in score_func_list:\n",
    "            selector3 = SelectKBest(k = feature_number, score_func = score_func).fit(features_train_transformed, survival_classes_train)\n",
    "            features_train_transformed_selected = selector3.transform(features_train_transformed) \n",
    "            features_train_transformed_selected = pd.DataFrame(features_train_transformed_selected) \n",
    "            features_train_transformed_selected_list.append(features_train_transformed_selected)\n",
    "            features_test_transformed_selected = selector3.transform(features_test_transformed)\n",
    "            features_test_transformed_selected = pd.DataFrame(features_test_transformed_selected)\n",
    "            features_test_transformed_selected_list.append(features_test_transformed_selected)\n",
    "    features_zipped = zip(features_train_transformed_selected_list, features_test_transformed_selected_list)\n",
    "\n",
    "    ### Training and prediction algorithm \n",
    "    for clf, parameters, scores in list_combined:\n",
    "        counter = 0 # Feature number counter  \n",
    "        counter2 = 0 # Feature selection method counter, 1 = ANOVA F-score, 2 = Mutial Information, 3 = Chi^2 \n",
    "        for x1,x2  in features_zipped:\n",
    "            if parameters == None: # Classifiers without hyperparameters skip tuning step\n",
    "                best_clf = clf.fit(x1, survival_classes_train)\n",
    "            else: # Classifier with hyperparameters are tuned with cross validation \n",
    "                scorer = make_scorer(roc_auc_score)\n",
    "                grid_obj = GridSearchCV(clf, parameters, scorer, cv = cv)  \n",
    "                grid_fit = grid_obj.fit(x1, survival_classes_train)\n",
    "                best_clf = grid_fit.best_estimator_\n",
    "            print best_clf # for debugging purposes\n",
    "            clf_name = best_clf.__class__.__name__\n",
    "            counter += 10   \n",
    "            counter2 += 1 \n",
    "            if counter2 == 1: # ANOVA F-score\n",
    "                b = roc_auc_score(survival_classes_test, best_clf.predict(x2))\n",
    "                scores['A' + str(counter)].append(b)\n",
    "                print str(clf_name) + ' ' + str(counter) + ' ANOVA features:' + \" score = \" + str(b) # for debugging purposes\n",
    "                counter -= 10\n",
    "            elif counter2 == 2: # Mutual Information\n",
    "                b = roc_auc_score(survival_classes_test, best_clf.predict(x2))\n",
    "                scores['M' + str(counter)].append(b)\n",
    "                print str(clf_name) + ' ' + str(counter) + ' MI features:' + \" score = \" + str(b) # for debugging purposes\n",
    "                counter -= 10\n",
    "            elif counter2 == 3: # Chi^2\n",
    "                b = roc_auc_score(survival_classes_test, best_clf.predict(x2))\n",
    "                scores['C' + str(counter)].append(b)\n",
    "                print str(clf_name) + ' ' + str(counter) + ' CHI features:' + \" score = \" + str(b) # for debugging purposes\n",
    "                counter2 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics Table\n",
    "Basic statistical information (mean, median, std) for the generated list over 10 iterations of AUC values for each classifier/feature selection combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Feat_selection</th>\n",
       "      <th>Feat_number</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Med</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>0.581887</td>\n",
       "      <td>0.579971</td>\n",
       "      <td>0.075107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>0.560582</td>\n",
       "      <td>0.590278</td>\n",
       "      <td>0.085321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>0.591600</td>\n",
       "      <td>0.590278</td>\n",
       "      <td>0.074697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>0.577931</td>\n",
       "      <td>0.581944</td>\n",
       "      <td>0.057518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>0.575798</td>\n",
       "      <td>0.534524</td>\n",
       "      <td>0.102676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Classifier Feat_selection Feat_number      Mean       Med  \\\n",
       "0  RandomForestClassifier              A          10  0.581887  0.579971   \n",
       "1              GaussianNB              A          10  0.560582  0.590278   \n",
       "2  DecisionTreeClassifier              A          10  0.591600  0.590278   \n",
       "3           MLPClassifier              A          10  0.577931  0.581944   \n",
       "4       BaggingClassifier              A          10  0.575798  0.534524   \n",
       "\n",
       "        Std  \n",
       "0  0.075107  \n",
       "1  0.085321  \n",
       "2  0.074697  \n",
       "3  0.057518  \n",
       "4  0.102676  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_combs = ['A10', 'A20', 'A30', 'A40', 'M10', 'M20', 'M30', 'M40', 'C10', 'C20', 'C30', 'C40']\n",
    "basicstats = []\n",
    "for feat_comb in feat_combs: \n",
    "    d = pd.DataFrame([[str(clf.__class__.__name__), feat_comb[0], feat_comb[1:3], np.mean(scores[feat_comb]), np.median(scores[feat_comb]), \n",
    "                       np.std(scores[feat_comb])] for clf, scores in zip(clf_list, scores_list)])\n",
    "    basicstats.append(d)\n",
    "basicstats = pd.concat(basicstats, axis=0)\n",
    "basicstats.columns = ['Classifier', 'Feat_selection', 'Feat_number', 'Mean', 'Med', 'Std']\n",
    "basicstats.reset_index(inplace=True)\n",
    "del basicstats['index']\n",
    "\n",
    "basicstats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Method vs. Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>MLPClassifier</th>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature Selection Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.601848</td>\n",
       "      <td>0.531607</td>\n",
       "      <td>0.595465</td>\n",
       "      <td>0.560276</td>\n",
       "      <td>0.598439</td>\n",
       "      <td>0.603467</td>\n",
       "      <td>0.568613</td>\n",
       "      <td>0.552138</td>\n",
       "      <td>0.564249</td>\n",
       "      <td>0.517873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.620080</td>\n",
       "      <td>0.453084</td>\n",
       "      <td>0.578143</td>\n",
       "      <td>0.527180</td>\n",
       "      <td>0.621125</td>\n",
       "      <td>0.597004</td>\n",
       "      <td>0.536411</td>\n",
       "      <td>0.545690</td>\n",
       "      <td>0.539952</td>\n",
       "      <td>0.483878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.617452</td>\n",
       "      <td>0.505777</td>\n",
       "      <td>0.588835</td>\n",
       "      <td>0.565378</td>\n",
       "      <td>0.612970</td>\n",
       "      <td>0.645063</td>\n",
       "      <td>0.566777</td>\n",
       "      <td>0.560044</td>\n",
       "      <td>0.565159</td>\n",
       "      <td>0.503280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          RandomForestClassifier  GaussianNB  \\\n",
       "Feature Selection Method                                       \n",
       "A                                       0.601848    0.531607   \n",
       "M                                       0.620080    0.453084   \n",
       "C                                       0.617452    0.505777   \n",
       "\n",
       "                          DecisionTreeClassifier  MLPClassifier  \\\n",
       "Feature Selection Method                                          \n",
       "A                                       0.595465       0.560276   \n",
       "M                                       0.578143       0.527180   \n",
       "C                                       0.588835       0.565378   \n",
       "\n",
       "                          BaggingClassifier  GradientBoostingClassifier  \\\n",
       "Feature Selection Method                                                  \n",
       "A                                  0.598439                    0.603467   \n",
       "M                                  0.621125                    0.597004   \n",
       "C                                  0.612970                    0.645063   \n",
       "\n",
       "                               SVC  LogisticRegression  KNeighborsClassifier  \\\n",
       "Feature Selection Method                                                       \n",
       "A                         0.568613            0.552138              0.564249   \n",
       "M                         0.536411            0.545690              0.539952   \n",
       "C                         0.566777            0.560044              0.565159   \n",
       "\n",
       "                          QuadraticDiscriminantAnalysis  \n",
       "Feature Selection Method                                 \n",
       "A                                              0.517873  \n",
       "M                                              0.483878  \n",
       "C                                              0.503280  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Feature selection method averaged over feature numbers table\n",
    "fsm_list = ['A', 'M', 'C']\n",
    "df = pd.DataFrame(index = fsm_list, columns=[clf.__class__.__name__ for clf in clf_list])\n",
    "for fsm in fsm_list:\n",
    "    for clf, scores in zip (clf_list, scores_list):\n",
    "        df.set_value(str(fsm), str(clf.__class__.__name__), \n",
    "                     np.mean(\n",
    "                         [np.mean(scores[key]) for key in scores if fsm in key]\n",
    "                     ) # feature selection method averaged over number of features (10,20,30,40)\n",
    "                    ) \n",
    "df.index.name = 'Feature Selection Method'\n",
    "df = df[df.columns].astype(float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.text.Text at 0x118344450>, <matplotlib.text.Text at 0x118572290>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAGFCAYAAAD+ekgbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUBx+oVAo9Aj/H+762RUrVGFcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1185cb7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Heatmap plot \n",
    "heatmap1 = sns.heatmap(df, cmap=\"coolwarm\", annot= True, cbar_kws={'label': 'AUC'})\n",
    "heatmap1.set(xlabel='Classifier', ylabel='Feature Selection Method')\n",
    "\n",
    "#fig = heatmap1.get_figure()  \n",
    "#fig.savefig(\"FSheatmap_6-6-17.pdf\", bbox_inches='tight') # Uncomment to save "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Number vs. Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>MLPClassifier</th>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.596749</td>\n",
       "      <td>0.505613</td>\n",
       "      <td>0.583132</td>\n",
       "      <td>0.564060</td>\n",
       "      <td>0.595456</td>\n",
       "      <td>0.598943</td>\n",
       "      <td>0.562754</td>\n",
       "      <td>0.564718</td>\n",
       "      <td>0.567019</td>\n",
       "      <td>0.496604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.613996</td>\n",
       "      <td>0.501808</td>\n",
       "      <td>0.590705</td>\n",
       "      <td>0.546061</td>\n",
       "      <td>0.612508</td>\n",
       "      <td>0.621957</td>\n",
       "      <td>0.559639</td>\n",
       "      <td>0.565635</td>\n",
       "      <td>0.561654</td>\n",
       "      <td>0.514089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.616506</td>\n",
       "      <td>0.491876</td>\n",
       "      <td>0.606879</td>\n",
       "      <td>0.543045</td>\n",
       "      <td>0.610218</td>\n",
       "      <td>0.616072</td>\n",
       "      <td>0.549835</td>\n",
       "      <td>0.540827</td>\n",
       "      <td>0.553436</td>\n",
       "      <td>0.494636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.625256</td>\n",
       "      <td>0.487993</td>\n",
       "      <td>0.569208</td>\n",
       "      <td>0.550613</td>\n",
       "      <td>0.625197</td>\n",
       "      <td>0.623739</td>\n",
       "      <td>0.556839</td>\n",
       "      <td>0.539315</td>\n",
       "      <td>0.543704</td>\n",
       "      <td>0.501378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                RandomForestClassifier  GaussianNB  DecisionTreeClassifier  \\\n",
       "Feature Number                                                               \n",
       "10                            0.596749    0.505613                0.583132   \n",
       "20                            0.613996    0.501808                0.590705   \n",
       "30                            0.616506    0.491876                0.606879   \n",
       "40                            0.625256    0.487993                0.569208   \n",
       "\n",
       "                MLPClassifier  BaggingClassifier  GradientBoostingClassifier  \\\n",
       "Feature Number                                                                 \n",
       "10                   0.564060           0.595456                    0.598943   \n",
       "20                   0.546061           0.612508                    0.621957   \n",
       "30                   0.543045           0.610218                    0.616072   \n",
       "40                   0.550613           0.625197                    0.623739   \n",
       "\n",
       "                     SVC  LogisticRegression  KNeighborsClassifier  \\\n",
       "Feature Number                                                       \n",
       "10              0.562754            0.564718              0.567019   \n",
       "20              0.559639            0.565635              0.561654   \n",
       "30              0.549835            0.540827              0.553436   \n",
       "40              0.556839            0.539315              0.543704   \n",
       "\n",
       "                QuadraticDiscriminantAnalysis  \n",
       "Feature Number                                 \n",
       "10                                   0.496604  \n",
       "20                                   0.514089  \n",
       "30                                   0.494636  \n",
       "40                                   0.501378  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Feature number average over feature selection methods table\n",
    "fn_list = ['10', '20', '30', '40']\n",
    "df2 = pd.DataFrame(index = fn_list, columns = [clf.__class__.__name__ for clf in clf_list])\n",
    "for fn in fn_list:\n",
    "    for clf, scores in zip (clf_list,scores_list):\n",
    "        df2.set_value(str(fn), str(clf.__class__.__name__), \n",
    "                     np.mean(\n",
    "                         [np.mean(scores[key]) for key in scores if fn in key]\n",
    "                     ) # mean across means of each A10 M10 C10 \n",
    "                    )\n",
    "df2.index.name = 'Feature Number'\n",
    "df2 = df2[df2.columns].astype(float)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAGICAYAAABMYefvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIFDg/D8MkTMvYokVJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1181b5a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Heatmap plot\n",
    "heatmap2 = sns.heatmap(df2, cmap=\"coolwarm\", annot= True, cbar_kws={'label': 'AUC'})\n",
    "heatmap2.set(xlabel='Classifier', ylabel='Feature Number')\n",
    "heatmap2.invert_yaxis()\n",
    "\n",
    "#fig = heatmap2.get_figure() \n",
    "#fig.savefig(\"FNheatmap_6-6-17.pdf\", bbox_inches='tight') # Uncomment to save "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representative Performance and Stablity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC median: 0.556860057324\n",
      "RSD median: 12.8925037242\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>AUC mean composite</th>\n",
       "      <th>AUC std composite</th>\n",
       "      <th>RSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.613127</td>\n",
       "      <td>0.0713154</td>\n",
       "      <td>11.6314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.496823</td>\n",
       "      <td>0.0757826</td>\n",
       "      <td>15.2535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.587481</td>\n",
       "      <td>0.0705103</td>\n",
       "      <td>12.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.550945</td>\n",
       "      <td>0.0692143</td>\n",
       "      <td>12.5629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.610845</td>\n",
       "      <td>0.0889885</td>\n",
       "      <td>14.5681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.615178</td>\n",
       "      <td>0.0689629</td>\n",
       "      <td>11.2102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.557267</td>\n",
       "      <td>0.0814295</td>\n",
       "      <td>14.6123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.552624</td>\n",
       "      <td>0.0643912</td>\n",
       "      <td>11.6519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.556453</td>\n",
       "      <td>0.0735751</td>\n",
       "      <td>13.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.501677</td>\n",
       "      <td>0.0817336</td>\n",
       "      <td>16.2921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Classifier AUC mean composite AUC std composite      RSD\n",
       "0         RandomForestClassifier           0.613127         0.0713154  11.6314\n",
       "1                     GaussianNB           0.496823         0.0757826  15.2535\n",
       "2         DecisionTreeClassifier           0.587481         0.0705103  12.0021\n",
       "3                  MLPClassifier           0.550945         0.0692143  12.5629\n",
       "4              BaggingClassifier           0.610845         0.0889885  14.5681\n",
       "5     GradientBoostingClassifier           0.615178         0.0689629  11.2102\n",
       "6                            SVC           0.557267         0.0814295  14.6123\n",
       "7             LogisticRegression           0.552624         0.0643912  11.6519\n",
       "8           KNeighborsClassifier           0.556453         0.0735751  13.2222\n",
       "9  QuadraticDiscriminantAnalysis           0.501677         0.0817336  16.2921"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Representative RSD and AUC table for each classifier \n",
    "df3 = pd.DataFrame(index = [clf.__class__.__name__ for clf in clf_list], columns = ['AUC mean composite', 'AUC std composite', 'RSD'])\n",
    "for clf, scores in zip(clf_list,scores_list):\n",
    "    df3.set_value(clf.__class__.__name__, 'AUC mean composite', np.mean([np.mean(scores[key]) for key in scores])) #Averages across all AUC mean values in scores list to get final compostive AUC mean score\n",
    "    df3.set_value(clf.__class__.__name__, 'AUC std composite', np.mean([np.std(scores[key]) for key in scores])) #Averages across all AUC SD values in scores list to get final compostive SD score\n",
    "    df3.set_value(clf.__class__.__name__, 'RSD', ((np.mean([np.std(scores[key]) for key in scores])) / (np.mean([np.mean(scores[key]) for key in scores])))*100) # might be able to just add later like so: df['$/hour'] = df['$']/df['hours']\n",
    "\n",
    "AUC_median = df3[\"AUC mean composite\"].median() # Will use median values in plot in next cell\n",
    "print \"AUC median: \" + str(AUC_median)\n",
    "RSD_median = df3['RSD'].median()\n",
    "print \"RSD median: \" + str(RSD_median)\n",
    "\n",
    "df3.index.name = 'Classifier'\n",
    "df3.reset_index(inplace=True)\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplot of representative performance and stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.patches.Rectangle at 0x118ce8f10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAFgCAYAAABT6LtsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1183f1290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "# Create scatterplot\n",
    "lm = sns.lmplot(x=\"RSD\", y=\"AUC mean composite\", hue = 'Classifier', data = df3, fit_reg=False, scatter_kws={\"s\": 100})\n",
    "\n",
    "# Set labels\n",
    "lm.set_ylabels('Performance (AUC)')\n",
    "lm.set_xlabels('Relative standard deviation of AUC (%)')\n",
    "\n",
    "# Get axis extrema to draw lines and boxes\n",
    "axes = plt.gca()\n",
    "y_min, y_max = axes.get_ylim()\n",
    "x_min, x_max = axes.get_xlim()\n",
    "\n",
    "# Plot median lines for AUC and RSD + highlighted area for classifiers with AUC > median and RSD < median\n",
    "plt.axhline(y= AUC_median, linewidth=1, color = 'red', alpha=0.5)\n",
    "plt.axvline(x= RSD_median, linewidth=1, color = 'red', alpha=0.5)\n",
    "lm.axes[0][0].add_patch(patches.Rectangle((RSD_median, AUC_median), -x_min, y_max,facecolor=\"red\", alpha = 0.05))\n",
    "\n",
    "#plt.savefig('Scatterplot_performance_RSD.pdf') # Uncomment to save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA\n",
    "Multivariate Analaysis of Variance (ANOVA) of AUC explained by the experimental factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experimental Factors</th>\n",
       "      <th>% Variance</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C(Classifier)</td>\n",
       "      <td>75.459645</td>\n",
       "      <td>9.0</td>\n",
       "      <td>59.440678</td>\n",
       "      <td>8.062597e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C(Feat_selection)</td>\n",
       "      <td>4.555413</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.147648</td>\n",
       "      <td>3.184045e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C(Feat_number)</td>\n",
       "      <td>0.326473</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.771502</td>\n",
       "      <td>5.150107e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C(Classifier):C(Feat_number)</td>\n",
       "      <td>3.909578</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.026544</td>\n",
       "      <td>4.540735e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C(Feat_selection):C(Feat_number)</td>\n",
       "      <td>0.877544</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.036882</td>\n",
       "      <td>4.118871e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C(Classifier):C(Feat_selection)</td>\n",
       "      <td>7.254377</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.857190</td>\n",
       "      <td>1.503115e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Residual</td>\n",
       "      <td>7.616970</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Experimental Factors  % Variance    df          F        PR(>F)\n",
       "0                     C(Classifier)   75.459645   9.0  59.440678  8.062597e-25\n",
       "1                 C(Feat_selection)    4.555413   2.0  16.147648  3.184045e-06\n",
       "2                    C(Feat_number)    0.326473   3.0   0.771502  5.150107e-01\n",
       "3      C(Classifier):C(Feat_number)    3.909578  27.0   1.026544  4.540735e-01\n",
       "4  C(Feat_selection):C(Feat_number)    0.877544   6.0   1.036882  4.118871e-01\n",
       "5   C(Classifier):C(Feat_selection)    7.254377  18.0   2.857190  1.503115e-03\n",
       "6                          Residual    7.616970  54.0        NaN           NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Fit linear model \n",
    "cw_lm = smf.ols('Mean ~ C(Classifier) + C(Feat_selection) + C(Feat_number) + C(Classifier)*C(Feat_number) + \\\n",
    "                C(Feat_selection)*C(Feat_number) + C(Classifier)*C(Feat_selection)', data=basicstats).fit() #Specify C for Categorical\n",
    "\n",
    "# Create ANOVA from linear model \n",
    "anova = anova_lm(cw_lm, typ=2)\n",
    "anova.index.name = 'Experimental Factors'\n",
    "anova.reset_index(inplace=True)\n",
    "anova['sum_sq'] = anova['sum_sq'].apply(lambda x: (x / anova['sum_sq'].sum())*100) # Tranform sum sq to % variance\n",
    "anova = anova.rename(columns={'sum_sq': '% Variance'}) # Rename to variance \n",
    "\n",
    "anova "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplot for ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.text.Text at 0x11ab12690>,\n",
       " <matplotlib.text.Text at 0x11ab1c810>,\n",
       " <matplotlib.text.Text at 0x11ab12590>,\n",
       " <matplotlib.text.Text at 0x11aafda50>,\n",
       " <matplotlib.text.Text at 0x11aaf4c10>,\n",
       " <matplotlib.text.Text at 0x1191c5410>,\n",
       " <matplotlib.text.Text at 0x11abab310>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAGVCAYAAAASbiG+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNzOrESd9M7Ma+f9pyfPG3ysjVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1183ea190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creat bar plot for ANOVA factors \n",
    "anovaplot = sns.barplot(x=\"Experimental Factors\", y=\"% Variance\", data=anova)\n",
    "\n",
    "# Change labels \n",
    "anovaplot.set_ylabel('Variance (%)')\n",
    "anovaplot.set_xticklabels(['Classifier', 'Feature Selection', 'Feature Number', 'Classifier:Feature Number', \\\n",
    "                           'Feature selection:Feature Number', 'Classifier:Feature Selection', 'Residual'], rotation=90)\n",
    "\n",
    "#fig = anovaplot.get_figure()\n",
    "#fig.savefig(\"Variation_graph_6-8-17.pdf\", bbox_inches='tight') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
